<!DOCTYPE html>
<!-- saved from url=(0047)https://docs.gpt4all.io/gpt4all_python/ref.html -->
<html lang="en" class="js-focus-visible js" data-js-focus-visible=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
      
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="GPT4All Docs - run LLMs efficiently on your hardware">
      
      
      
        
      
      
        
      
      
        
      
      
      <link rel="icon" href="https://docs.gpt4all.io/assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.34">
    
    
      
        
      
    
    
      <link rel="stylesheet" href="./SDK Reference - GPT4All_files/main.35f28582.min.css">
      
        
        <link rel="stylesheet" href="./SDK Reference - GPT4All_files/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="">
        <link rel="stylesheet" href="./SDK Reference - GPT4All_files/css">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="./SDK Reference - GPT4All_files/_mkdocstrings.css">
    
      <link rel="stylesheet" href="./SDK Reference - GPT4All_files/custom.css">
    
    
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-NPXC8BYHJV"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-NPXC8BYHJV",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-NPXC8BYHJV",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta property="og:type" content="website">
      
        
      
        <meta property="og:description" content="GPT4All Docs - run LLMs efficiently on your hardware">
      
        
      
        <meta property="og:image:type" content="image/png">
      
        <meta property="og:image:width" content="1200">
      
        <meta property="og:image:height" content="630">
      
        
      
        <meta name="twitter:card" content="summary_large_image">
      
        
      
        <meta name="twitter:description" content="GPT4All Docs - run LLMs efficiently on your hardware">
      
        
      
    
    
  <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link rel="canonical" href="https://docs.gpt4all.io/gpt4all_python/ref.html"><link rel="prev" href="https://docs.gpt4all.io/gpt4all_python/monitoring.html"><link rel="next" href="https://docs.gpt4all.io/gpt4all_help/faq.html"><title>SDK Reference - GPT4All</title><meta property="og:title" content="SDK Reference - GPT4All"><meta property="og:image" content="https://docs.gpt4all.io/assets/images/social/gpt4all_python/ref.png"><meta property="og:url" content="https://docs.gpt4all.io/gpt4all_python/ref.html"><meta name="twitter:title" content="SDK Reference - GPT4All"><meta name="twitter:image" content="https://docs.gpt4all.io/assets/images/social/gpt4all_python/ref.png"></head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all-python-sdk-reference" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://docs.gpt4all.io/index.html" title="GPT4All" class="md-header__button md-logo" aria-label="GPT4All" data-md-component="logo">
      
  <img src="./SDK Reference - GPT4All_files/nomic.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            GPT4All
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              SDK Reference
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required="">
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0">
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">Type to start searching</div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/nomic-ai/gpt4all" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
  </div>
  <div class="md-source__repository md-source__repository--active">
    nomic-ai/gpt4all
  <ul class="md-source__facts"><li class="md-source__fact md-source__fact--version">v3.2.1</li><li class="md-source__fact md-source__fact--stars">69k</li><li class="md-source__fact md-source__fact--forks">7.6k</li></ul></div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" style="top: 53px;">
                <div class="md-sidebar__scrollwrap" style="height: 815px;">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://docs.gpt4all.io/index.html" title="GPT4All" class="md-nav__button md-logo" aria-label="GPT4All" data-md-component="logo">
      
  <img src="./SDK Reference - GPT4All_files/nomic.png" alt="logo">

    </a>
    GPT4All
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nomic-ai/gpt4all" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
  </div>
  <div class="md-source__repository">
    nomic-ai/gpt4all
  </div>
</a>
    </div>
  
  <ul class="md-nav__list">
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPT4All Documentation
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/quickstart.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/chats.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chats
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/models.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/localdocs.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LocalDocs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/settings.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Settings
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7">
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Cookbook
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Cookbook
          </label>
          <ul class="md-nav__list">
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/cookbook/use-local-ai-models-to-privately-chat-with-google-drive.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Local AI Chat with your Google Drive
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/cookbook/use-local-ai-models-to-privately-chat-with-Obsidian.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Local AI Chat with your Obsidian Vault
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_desktop/cookbook/use-local-ai-models-to-privately-chat-with-One-Drive.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Local AI Chat with your OneDrive
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" checked="">
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Python SDK
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Python SDK
          </label>
          <ul class="md-nav__list">
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_python/home.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPT4All Python SDK
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_python/monitoring.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Monitoring
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    SDK Reference
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="https://docs.gpt4all.io/gpt4all_python/ref.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    SDK Reference
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc">
      
        <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All" class="md-nav__link">
    <span class="md-ellipsis">
      GPT4All
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GPT4All">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.backend" class="md-nav__link">
    <span class="md-ellipsis">
      backend
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.device" class="md-nav__link">
    <span class="md-ellipsis">
      device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.chat_session" class="md-nav__link">
    <span class="md-ellipsis">
      chat_session
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.close" class="md-nav__link">
    <span class="md-ellipsis">
      close
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.download_model" class="md-nav__link">
    <span class="md-ellipsis">
      download_model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.list_gpus" class="md-nav__link">
    <span class="md-ellipsis">
      list_gpus
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.list_models" class="md-nav__link">
    <span class="md-ellipsis">
      list_models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.retrieve_model" class="md-nav__link">
    <span class="md-ellipsis">
      retrieve_model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All" class="md-nav__link">
    <span class="md-ellipsis">
      Embed4All
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Embed4All">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All.close" class="md-nav__link">
    <span class="md-ellipsis">
      close
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All.embed" class="md-nav__link">
    <span class="md-ellipsis">
      embed
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9">
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Help
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Help
          </label>
          <ul class="md-nav__list">
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_help/faq.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.gpt4all.io/gpt4all_help/troubleshooting.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Troubleshooting
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" style="top: 53px;">
                <div class="md-sidebar__scrollwrap" style="height: 815px;">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc">
      
        <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All" class="md-nav__link">
    <span class="md-ellipsis">
      GPT4All
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GPT4All">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.backend" class="md-nav__link">
    <span class="md-ellipsis">
      backend
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.device" class="md-nav__link">
    <span class="md-ellipsis">
      device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.chat_session" class="md-nav__link">
    <span class="md-ellipsis">
      chat_session
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.close" class="md-nav__link">
    <span class="md-ellipsis">
      close
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.download_model" class="md-nav__link">
    <span class="md-ellipsis">
      download_model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.list_gpus" class="md-nav__link">
    <span class="md-ellipsis">
      list_gpus
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.list_models" class="md-nav__link">
    <span class="md-ellipsis">
      list_models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.GPT4All.retrieve_model" class="md-nav__link">
    <span class="md-ellipsis">
      retrieve_model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All" class="md-nav__link">
    <span class="md-ellipsis">
      Embed4All
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Embed4All">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All.close" class="md-nav__link">
    <span class="md-ellipsis">
      close
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="https://docs.gpt4all.io/gpt4all_python/ref.html#gpt4all.gpt4all.Embed4All.embed" class="md-nav__link">
    <span class="md-ellipsis">
      embed
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="gpt4all-python-sdk-reference">GPT4All Python SDK Reference</h1>


<div class="doc doc-object doc-class">



<h4 id="gpt4all.gpt4all.GPT4All" class="doc doc-heading">
            <code>GPT4All</code>


</h4>


    <div class="doc doc-contents first">


        <p>Python class that handles instantiation, downloading, generation and chat with GPT4All models.</p>

              <details class="quote">
                <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-163">163</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-164">164</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-165">165</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-166">166</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-167">167</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-168">168</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-169">169</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-170">170</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-171">171</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-172">172</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-173">173</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-174">174</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-175">175</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-176">176</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-177">177</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-178">178</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-179">179</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-180">180</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-181">181</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-182">182</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-183">183</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-184">184</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-185">185</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-186">186</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-187">187</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-188">188</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-189">189</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-190">190</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-191">191</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-192">192</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-193">193</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-194">194</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-195">195</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-196">196</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-197">197</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-198">198</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-199">199</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-200">200</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-201">201</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-202">202</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-203">203</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-204">204</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-205">205</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-206">206</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-207">207</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-208">208</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-209">209</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-210">210</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-211">211</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-212">212</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-213">213</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-214">214</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-215">215</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-216">216</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-217">217</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-218">218</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-219">219</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-220">220</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-221">221</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-222">222</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-223">223</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-224">224</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-225">225</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-226">226</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-227">227</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-228">228</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-229">229</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-230">230</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-231">231</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-232">232</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-233">233</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-234">234</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-235">235</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-236">236</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-237">237</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-238">238</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-239">239</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-240">240</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-241">241</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-242">242</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-243">243</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-244">244</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-245">245</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-246">246</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-247">247</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-248">248</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-249">249</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-250">250</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-251">251</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-252">252</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-253">253</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-254">254</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-255">255</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-256">256</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-257">257</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-258">258</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-259">259</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-260">260</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-261">261</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-262">262</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-263">263</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-264">264</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-265">265</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-266">266</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-267">267</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-268">268</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-269">269</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-270">270</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-271">271</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-272">272</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-273">273</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-274">274</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-275">275</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-276">276</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-277">277</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-278">278</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-279">279</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-280">280</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-281">281</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-282">282</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-283">283</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-284">284</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-285">285</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-286">286</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-287">287</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-288">288</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-289">289</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-290">290</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-291">291</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-292">292</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-293">293</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-294">294</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-295">295</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-296">296</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-297">297</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-298">298</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-299">299</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-300">300</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-301">301</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-302">302</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-303">303</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-304">304</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-305">305</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-306">306</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-307">307</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-308">308</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-309">309</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-310">310</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-311">311</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-312">312</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-313">313</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-314">314</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-315">315</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-316">316</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-317">317</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-318">318</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-319">319</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-320">320</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-321">321</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-322">322</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-323">323</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-324">324</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-325">325</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-326">326</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-327">327</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-328">328</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-329">329</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-330">330</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-331">331</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-332">332</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-333">333</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-334">334</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-335">335</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-336">336</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-337">337</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-338">338</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-339">339</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-340">340</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-341">341</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-342">342</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-343">343</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-344">344</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-345">345</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-346">346</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-347">347</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-348">348</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-349">349</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-350">350</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-351">351</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-352">352</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-353">353</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-354">354</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-355">355</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-356">356</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-357">357</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-358">358</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-359">359</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-360">360</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-361">361</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-362">362</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-363">363</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-364">364</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-365">365</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-366">366</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-367">367</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-368">368</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-369">369</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-370">370</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-371">371</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-372">372</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-373">373</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-374">374</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-375">375</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-376">376</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-377">377</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-378">378</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-379">379</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-380">380</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-381">381</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-382">382</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-383">383</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-384">384</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-385">385</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-386">386</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-387">387</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-388">388</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-389">389</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-390">390</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-391">391</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-392">392</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-393">393</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-394">394</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-395">395</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-396">396</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-397">397</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-398">398</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-399">399</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-400">400</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-401">401</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-402">402</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-403">403</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-404">404</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-405">405</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-406">406</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-407">407</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-408">408</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-409">409</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-410">410</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-411">411</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-412">412</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-413">413</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-414">414</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-415">415</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-416">416</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-417">417</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-418">418</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-419">419</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-420">420</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-421">421</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-422">422</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-423">423</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-424">424</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-425">425</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-426">426</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-427">427</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-428">428</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-429">429</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-430">430</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-431">431</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-432">432</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-433">433</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-434">434</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-435">435</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-436">436</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-437">437</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-438">438</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-439">439</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-440">440</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-441">441</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-442">442</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-443">443</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-444">444</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-445">445</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-446">446</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-447">447</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-448">448</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-449">449</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-450">450</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-451">451</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-452">452</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-453">453</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-454">454</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-455">455</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-456">456</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-457">457</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-458">458</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-459">459</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-460">460</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-461">461</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-462">462</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-463">463</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-464">464</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-465">465</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-466">466</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-467">467</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-468">468</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-469">469</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-470">470</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-471">471</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-472">472</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-473">473</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-474">474</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-475">475</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-476">476</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-477">477</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-478">478</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-479">479</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-480">480</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-481">481</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-482">482</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-483">483</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-484">484</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-485">485</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-486">486</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-487">487</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-488">488</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-489">489</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-490">490</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-491">491</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-492">492</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-493">493</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-494">494</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-495">495</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-496">496</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-497">497</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-498">498</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-499">499</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-500">500</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-501">501</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-502">502</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-503">503</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-504">504</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-505">505</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-506">506</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-507">507</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-508">508</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-509">509</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-510">510</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-511">511</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-512">512</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-513">513</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-514">514</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-515">515</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-516">516</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-517">517</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-518">518</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-519">519</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-520">520</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-521">521</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-522">522</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-523">523</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-524">524</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-525">525</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-526">526</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-527">527</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-528">528</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-529">529</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-530">530</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-531">531</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-532">532</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-533">533</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-534">534</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-535">535</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-536">536</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-537">537</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-538">538</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-539">539</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-540">540</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-541">541</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-542">542</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-543">543</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-544">544</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-545">545</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-546">546</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-547">547</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-548">548</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-549">549</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-550">550</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-551">551</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-552">552</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-553">553</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-554">554</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-555">555</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-556">556</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-557">557</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-558">558</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-559">559</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-560">560</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-561">561</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-562">562</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-563">563</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-564">564</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-565">565</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-566">566</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-567">567</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-568">568</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-569">569</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-570">570</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-571">571</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-572">572</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-573">573</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-574">574</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-575">575</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-576">576</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-577">577</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-578">578</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-579">579</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-580">580</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-581">581</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-582">582</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-583">583</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-584">584</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-585">585</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-586">586</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-587">587</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-588">588</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-589">589</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-590">590</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-591">591</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-592">592</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-593">593</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-594">594</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-595">595</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-596">596</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-597">597</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-598">598</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-599">599</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-600">600</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-601">601</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-602">602</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-603">603</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-604">604</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-605">605</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-606">606</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-607">607</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-608">608</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-609">609</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-610">610</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-611">611</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-612">612</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-613">613</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-614">614</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-615">615</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-616">616</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-617">617</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-618">618</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-619">619</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-620">620</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-621">621</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-622">622</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-623">623</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-624">624</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-625">625</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-626">626</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-627">627</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-628">628</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-629">629</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-630">630</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-631">631</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-632">632</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-633">633</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-634">634</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-635">635</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-636">636</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-637">637</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-638">638</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-639">639</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-640">640</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-641">641</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-642">642</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-643">643</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-644">644</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-645">645</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-646">646</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-647">647</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-648">648</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-649">649</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-650">650</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-651">651</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-652">652</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-653">653</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-654">654</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-655">655</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-656">656</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-657">657</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-658">658</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-659">659</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-660">660</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-661">661</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-662">662</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-663">663</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-664">664</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-665">665</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-666">666</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-667">667</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-668">668</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-669">669</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-670">670</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-671">671</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-672">672</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-673">673</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-674">674</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-675">675</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-676">676</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-677">677</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-678">678</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-679">679</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-680">680</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-681">681</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-682">682</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-683">683</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-684">684</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-685">685</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-686">686</a></span></pre></div></td><td class="code"><div><pre id="__code_20"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_20 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="k">class</span> <span class="nc">GPT4All</span><span class="p">:</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">    Python class that handles instantiation, downloading, generation and chat with GPT4All models.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">    """</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="n">allow_download</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="n">n_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">n_ctx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="n">ngl</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="p">):</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        Constructor</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">            model_name: Name of GPT4All or custom model. Including ".gguf" file extension is optional but encouraged.</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">            model_path: Path to directory containing model file or, if file does not exist, where to download model.</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a><span class="sd">                Default is None, in which case models will be stored in `~/.cache/gpt4all/`.</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a><span class="sd">            model_type: Model architecture. This argument currently does not have any functionality and is just used as</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a><span class="sd">                descriptive identifier for user. Default is None.</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="sd">            allow_download: Allow API to download models from gpt4all.io. Default is True.</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="sd">            n_threads: number of CPU threads used by GPT4All. Default is None, then the number of threads are determined automatically.</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">            device: The processing unit on which the GPT4All model will run. It can be set to:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">                - "cpu": Model will run on the central processing unit.</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">                - "gpu": Use Metal on ARM64 macOS, otherwise the same as "kompute".</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">                - "kompute": Use the best GPU provided by the Kompute backend.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">                - "cuda": Use the best GPU provided by the CUDA backend.</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">                - "amd", "nvidia": Use the best GPU provided by the Kompute backend from this vendor.</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">                - A specific device name from the list returned by `GPT4All.list_gpus()`.</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">                Default is Metal on ARM64 macOS, "cpu" otherwise.</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">                Note: If a selected GPU device does not have sufficient RAM to accommodate the model, an error will be thrown, and the GPT4All instance will be rendered invalid. It's advised to ensure the device has enough memory before initiating the model.</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">            n_ctx: Maximum size of context window</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a><span class="sd">            ngl: Number of GPU layers to use (Vulkan)</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="sd">            verbose: If True, print debug messages.</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a><span class="sd">        """</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="n">model_type</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{0}</span><span class="s2">"</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>        <span class="n">device_init</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>        <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">"darwin"</span><span class="p">:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>            <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>                <span class="n">backend</span> <span class="o">=</span> <span class="s2">"auto"</span>  <span class="c1"># "auto" is effectively "metal" due to currently non-functional fallback</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>            <span class="k">elif</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">"cpu"</span><span class="p">:</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>                <span class="n">backend</span> <span class="o">=</span> <span class="s2">"cpu"</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>                <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">machine</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">"arm64"</span> <span class="ow">or</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"gpu"</span><span class="p">:</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unknown device for this platform: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>                <span class="n">backend</span> <span class="o">=</span> <span class="s2">"metal"</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">"kompute"</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>            <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">"cpu"</span><span class="p">:</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>                <span class="k">pass</span>  <span class="c1"># use kompute with no device</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>            <span class="k">elif</span> <span class="n">device</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="s2">"kompute"</span><span class="p">):</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>                <span class="n">backend</span> <span class="o">=</span> <span class="n">device</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>                <span class="n">device_init</span> <span class="o">=</span> <span class="s2">"gpu"</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>            <span class="k">elif</span> <span class="n">device</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"cuda:"</span><span class="p">):</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>                <span class="n">backend</span> <span class="o">=</span> <span class="s2">"cuda"</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>                <span class="n">device_init</span> <span class="o">=</span> <span class="n">_remove_prefix</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="s2">"cuda:"</span><span class="p">)</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>                <span class="n">device_init</span> <span class="o">=</span> <span class="n">_remove_prefix</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="s2">"kompute:"</span><span class="p">)</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>        <span class="c1"># Retrieve model and download if allowed</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> <span class="n">ConfigType</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">retrieve_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span> <span class="n">allow_download</span><span class="o">=</span><span class="n">allow_download</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">LLModel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"path"</span><span class="p">],</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="n">ngl</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>        <span class="k">if</span> <span class="n">device_init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_gpu</span><span class="p">(</span><span class="n">device_init</span><span class="p">)</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>        <span class="c1"># Set n_threads</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>        <span class="k">if</span> <span class="n">n_threads</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_thread_count</span><span class="p">(</span><span class="n">n_threads</span><span class="p">)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>        <span class="k">return</span> <span class="bp">self</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">typ</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="ne">BaseException</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="ne">BaseException</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tb</span><span class="p">:</span> <span class="n">TracebackType</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="w">        </span><span class="sd">"""Delete the model instance and free associated system resources."""</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>    <span class="k">def</span> <span class="nf">backend</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">"cpu"</span><span class="p">,</span> <span class="s2">"kompute"</span><span class="p">,</span> <span class="s2">"cuda"</span><span class="p">,</span> <span class="s2">"metal"</span><span class="p">]:</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a><span class="w">        </span><span class="sd">"""The name of the llama.cpp backend currently in use. One of "cpu", "kompute", "cuda", or "metal"."""</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">backend</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="w">        </span><span class="sd">"""The name of the GPU device currently in use, or None for backends other than Kompute or CUDA."""</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>    <span class="k">def</span> <span class="nf">current_chat_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>        <span class="k">return</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">)</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>    <span class="k">def</span> <span class="nf">list_models</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ConfigType</span><span class="p">]:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">        Fetch model list from https://gpt4all.io/models/models3.json.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">            Model list in JSON format.</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">        """</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>        <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"https://gpt4all.io/models/models3.json"</span><span class="p">)</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>        <span class="k">if</span> <span class="n">resp</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Request failed: HTTP </span><span class="si">{</span><span class="n">resp</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">resp</span><span class="o">.</span><span class="n">reason</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>        <span class="k">return</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>    <span class="nd">@classmethod</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>    <span class="k">def</span> <span class="nf">retrieve_model</span><span class="p">(</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>        <span class="bp">cls</span><span class="p">,</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>        <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>        <span class="n">allow_download</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ConfigType</span><span class="p">:</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">        Find model file, and if it doesn't exist, download the model.</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">            model_name: Name of model.</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">            model_path: Path to find model. Default is None in which case path is set to</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">                ~/.cache/gpt4all/.</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">            allow_download: Allow API to download model from gpt4all.io. Default is True.</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">            verbose: If True (default), print debug messages.</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="sd">            Model config.</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">        """</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a>        <span class="n">model_filename</span> <span class="o">=</span> <span class="n">append_extension_if_missing</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>        <span class="c1"># get the config for the model</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>        <span class="n">config</span><span class="p">:</span> <span class="n">ConfigType</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>        <span class="k">if</span> <span class="n">allow_download</span><span class="p">:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>            <span class="n">available_models</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_models</span><span class="p">()</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">available_models</span><span class="p">:</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>                <span class="k">if</span> <span class="n">model_filename</span> <span class="o">==</span> <span class="n">m</span><span class="p">[</span><span class="s2">"filename"</span><span class="p">]:</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>                    <span class="n">tmpl</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"promptTemplate"</span><span class="p">,</span> <span class="n">DEFAULT_PROMPT_TEMPLATE</span><span class="p">)</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>                    <span class="c1"># change to Python-style formatting</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>                    <span class="n">m</span><span class="p">[</span><span class="s2">"promptTemplate"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmpl</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"%1"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{0}</span><span class="s2">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"%2"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{1}</span><span class="s2">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>                    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>                    <span class="k">break</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>        <span class="c1"># Validate download directory</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>        <span class="k">if</span> <span class="n">model_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">DEFAULT_MODEL_DIRECTORY</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>            <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"Failed to create model download directory"</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>            <span class="n">model_path</span> <span class="o">=</span> <span class="n">DEFAULT_MODEL_DIRECTORY</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>            <span class="n">model_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">model_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model directory does not exist: </span><span class="si">{</span><span class="n">model_path</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>        <span class="n">model_dest</span> <span class="o">=</span> <span class="n">model_path</span> <span class="o">/</span> <span class="n">model_filename</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>        <span class="k">if</span> <span class="n">model_dest</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>            <span class="n">config</span><span class="p">[</span><span class="s2">"path"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_dest</span><span class="p">)</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Found model file at </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">model_dest</span><span class="p">)</span><span class="si">!r}</span><span class="s2">"</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>        <span class="k">elif</span> <span class="n">allow_download</span><span class="p">:</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>            <span class="c1"># If model file does not exist, download</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>            <span class="n">filesize</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"filesize"</span><span class="p">)</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>            <span class="n">config</span><span class="p">[</span><span class="s2">"path"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">download_model</span><span class="p">(</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>                <span class="n">model_filename</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"url"</span><span class="p">),</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>                <span class="n">expected_size</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">filesize</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">filesize</span><span class="p">),</span> <span class="n">expected_md5</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"md5sum"</span><span class="p">),</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>            <span class="p">))</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model file does not exist: </span><span class="si">{</span><span class="n">model_dest</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>        <span class="k">return</span> <span class="n">config</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>    <span class="k">def</span> <span class="nf">download_model</span><span class="p">(</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>        <span class="n">model_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>        <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>        <span class="n">url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>        <span class="n">expected_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>        <span class="n">expected_md5</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="sd">        Download model from gpt4all.io.</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a><span class="sd">            model_filename: Filename of model (with .gguf extension).</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a><span class="sd">            model_path: Path to download model to.</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a><span class="sd">            verbose: If True (default), print debug messages.</span>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a><span class="sd">            url: the models remote url (e.g. may be hosted on HF)</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a><span class="sd">            expected_size: The expected size of the download.</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a><span class="sd">            expected_md5: The expected MD5 hash of the download.</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="sd">            Model file destination.</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a><span class="sd">        """</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>        <span class="c1"># Download model</span>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>        <span class="k">if</span> <span class="n">url</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>            <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"https://gpt4all.io/models/gguf/</span><span class="si">{</span><span class="n">model_filename</span><span class="si">}</span><span class="s2">"</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>        <span class="k">def</span> <span class="nf">make_request</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>            <span class="n">headers</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a>            <span class="k">if</span> <span class="n">offset</span><span class="p">:</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a>                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Download interrupted, resuming from byte position </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>                <span class="n">headers</span><span class="p">[</span><span class="s1">'Range'</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'bytes=</span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s1">-'</span>  <span class="c1"># resume incomplete response</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a>                <span class="n">headers</span><span class="p">[</span><span class="s2">"Accept-Encoding"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"identity"</span>  <span class="c1"># Content-Encoding changes meaning of ranges</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a>            <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a>            <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">206</span><span class="p">):</span>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Request failed: HTTP </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">reason</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a>            <span class="k">if</span> <span class="n">offset</span> <span class="ow">and</span> <span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">206</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'Content-Range'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)):</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Connection was interrupted and server does not support range requests'</span><span class="p">)</span>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a>            <span class="k">if</span> <span class="p">(</span><span class="n">enc</span> <span class="o">:=</span> <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"Content-Encoding"</span><span class="p">))</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected identity Content-Encoding, got </span><span class="si">{</span><span class="n">enc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a>            <span class="k">return</span> <span class="n">response</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>        <span class="n">response</span> <span class="o">=</span> <span class="n">make_request</span><span class="p">()</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>        <span class="n">total_size_in_bytes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"content-length"</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>        <span class="n">block_size</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>  <span class="c1"># 1 MB</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>        <span class="n">partial_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">model_filename</span> <span class="o">+</span> <span class="s2">".part"</span><span class="p">)</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">partial_path</span><span class="p">,</span> <span class="s2">"w+b"</span><span class="p">)</span> <span class="k">as</span> <span class="n">partf</span><span class="p">:</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a>                <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s2">"Downloading"</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">total_size_in_bytes</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">"iB"</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress_bar</span><span class="p">:</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>                    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>                        <span class="n">last_progress</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>                        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>                            <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">block_size</span><span class="p">):</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>                                <span class="n">partf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>                                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>                        <span class="k">except</span> <span class="n">ChunkedEncodingError</span> <span class="k">as</span> <span class="n">cee</span><span class="p">:</span>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a>                            <span class="k">if</span> <span class="n">cee</span><span class="o">.</span><span class="n">args</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pe</span> <span class="o">:=</span> <span class="n">cee</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ProtocolError</span><span class="p">):</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>                                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pe</span><span class="o">.</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ir</span> <span class="o">:=</span> <span class="n">pe</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">IncompleteRead</span><span class="p">):</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>                                    <span class="k">assert</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">&lt;=</span> <span class="n">ir</span><span class="o">.</span><span class="n">partial</span>  <span class="c1"># urllib3 may be ahead of us but never behind</span>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a>                                    <span class="c1"># the socket was closed during a read - retry</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a>                                    <span class="n">response</span> <span class="o">=</span> <span class="n">make_request</span><span class="p">(</span><span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a>                                    <span class="k">continue</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a>                            <span class="k">raise</span>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>                        <span class="k">if</span> <span class="n">total_size_in_bytes</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">&lt;</span> <span class="n">total_size_in_bytes</span><span class="p">:</span>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>                            <span class="k">if</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">==</span> <span class="n">last_progress</span><span class="p">:</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>                                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"Download not making progress, aborting."</span><span class="p">)</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>                            <span class="c1"># server closed connection prematurely - retry</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>                            <span class="n">response</span> <span class="o">=</span> <span class="n">make_request</span><span class="p">(</span><span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>                            <span class="k">continue</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>                        <span class="k">break</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>                <span class="c1"># verify file integrity</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>                <span class="n">file_size</span> <span class="o">=</span> <span class="n">partf</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>                <span class="k">if</span> <span class="n">expected_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">file_size</span> <span class="o">!=</span> <span class="n">expected_size</span><span class="p">:</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected file size of </span><span class="si">{</span><span class="n">expected_size</span><span class="si">}</span><span class="s2"> bytes, got </span><span class="si">{</span><span class="n">file_size</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>                <span class="k">if</span> <span class="n">expected_md5</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>                    <span class="n">partf</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>                    <span class="n">hsh</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">()</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>                    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s2">"Verifying"</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">file_size</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">"iB"</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">bar</span><span class="p">:</span>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>                        <span class="k">while</span> <span class="n">chunk</span> <span class="o">:=</span> <span class="n">partf</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">block_size</span><span class="p">):</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>                            <span class="n">hsh</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>                            <span class="n">bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">))</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>                    <span class="k">if</span> <span class="n">hsh</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span> <span class="o">!=</span> <span class="n">expected_md5</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a>                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected MD5 hash of </span><span class="si">{</span><span class="n">expected_md5</span><span class="si">!r}</span><span class="s2">, got </span><span class="si">{</span><span class="n">hsh</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a>            <span class="k">except</span><span class="p">:</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a>                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>                    <span class="nb">print</span><span class="p">(</span><span class="s2">"Cleaning up the interrupted download..."</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>                <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>                    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">partial_path</span><span class="p">)</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>                <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a>                    <span class="k">pass</span>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a>                <span class="k">raise</span>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a>            <span class="c1"># flush buffers and sync the inode</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>            <span class="n">partf</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a>            <span class="n">_fsync</span><span class="p">(</span><span class="n">partf</span><span class="p">)</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a>        <span class="c1"># move to final destination</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a>        <span class="n">download_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span> <span class="o">/</span> <span class="n">model_filename</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a>            <span class="n">os</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">partial_path</span><span class="p">,</span> <span class="n">download_path</span><span class="p">)</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>        <span class="k">except</span> <span class="ne">FileExistsError</span><span class="p">:</span>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a>                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">partial_path</span><span class="p">)</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a>            <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a>                <span class="k">pass</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>            <span class="k">raise</span>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model downloaded to </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">download_path</span><span class="p">)</span><span class="si">!r}</span><span class="s2">"</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>        <span class="k">return</span> <span class="n">download_path</span>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-467" name="__codelineno-0-467"></a>    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
<a id="__codelineno-0-468" name="__codelineno-0-468"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a>        <span class="n">min_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">repeat_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">repeat_last_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">n_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a>        <span class="n">n_predict</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">streaming</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">callback</span><span class="p">:</span> <span class="n">ResponseCallbackType</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span> <span class="o">...</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a>    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a>        <span class="n">min_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">repeat_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">repeat_last_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">n_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a>        <span class="n">n_predict</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">streaming</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">],</span> <span class="n">callback</span><span class="p">:</span> <span class="n">ResponseCallbackType</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span> <span class="o">...</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a>    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a>        <span class="n">min_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">repeat_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">repeat_last_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">n_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a>        <span class="n">n_predict</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">streaming</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">callback</span><span class="p">:</span> <span class="n">ResponseCallbackType</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span> <span class="o">...</span>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a>    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a>        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a>        <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a>        <span class="n">top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">40</span><span class="p">,</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a>        <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>        <span class="n">min_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a>        <span class="n">repeat_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.18</span><span class="p">,</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>        <span class="n">repeat_last_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a>        <span class="n">n_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>        <span class="n">n_predict</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a>        <span class="n">streaming</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a>        <span class="n">callback</span><span class="p">:</span> <span class="n">ResponseCallbackType</span> <span class="o">=</span> <span class="n">empty_response_callback</span><span class="p">,</span>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-501" name="__codelineno-0-501"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-502" name="__codelineno-0-502"></a><span class="sd">        Generate outputs from any GPT4All model.</span>
<a id="__codelineno-0-503" name="__codelineno-0-503"></a>
<a id="__codelineno-0-504" name="__codelineno-0-504"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-505" name="__codelineno-0-505"></a><span class="sd">            prompt: The prompt for the model to complete.</span>
<a id="__codelineno-0-506" name="__codelineno-0-506"></a><span class="sd">            max_tokens: The maximum number of tokens to generate.</span>
<a id="__codelineno-0-507" name="__codelineno-0-507"></a><span class="sd">            temp: The model temperature. Larger values increase creativity but decrease factuality.</span>
<a id="__codelineno-0-508" name="__codelineno-0-508"></a><span class="sd">            top_k: Randomly sample from the top_k most likely tokens at each generation step. Set this to 1 for greedy decoding.</span>
<a id="__codelineno-0-509" name="__codelineno-0-509"></a><span class="sd">            top_p: Randomly sample at each generation step from the top most likely tokens whose probabilities add up to top_p.</span>
<a id="__codelineno-0-510" name="__codelineno-0-510"></a><span class="sd">            min_p: Randomly sample at each generation step from the top most likely tokens whose probabilities are at least min_p.</span>
<a id="__codelineno-0-511" name="__codelineno-0-511"></a><span class="sd">            repeat_penalty: Penalize the model for repetition. Higher values result in less repetition.</span>
<a id="__codelineno-0-512" name="__codelineno-0-512"></a><span class="sd">            repeat_last_n: How far in the models generation history to apply the repeat penalty.</span>
<a id="__codelineno-0-513" name="__codelineno-0-513"></a><span class="sd">            n_batch: Number of prompt tokens processed in parallel. Larger values decrease latency but increase resource requirements.</span>
<a id="__codelineno-0-514" name="__codelineno-0-514"></a><span class="sd">            n_predict: Equivalent to max_tokens, exists for backwards compatibility.</span>
<a id="__codelineno-0-515" name="__codelineno-0-515"></a><span class="sd">            streaming: If True, this method will instead return a generator that yields tokens as the model generates them.</span>
<a id="__codelineno-0-516" name="__codelineno-0-516"></a><span class="sd">            callback: A function with arguments token_id:int and response:str, which receives the tokens from the model as they are generated and stops the generation by returning False.</span>
<a id="__codelineno-0-517" name="__codelineno-0-517"></a>
<a id="__codelineno-0-518" name="__codelineno-0-518"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-519" name="__codelineno-0-519"></a><span class="sd">            Either the entire completion or a generator that yields the completion token by token.</span>
<a id="__codelineno-0-520" name="__codelineno-0-520"></a><span class="sd">        """</span>
<a id="__codelineno-0-521" name="__codelineno-0-521"></a>
<a id="__codelineno-0-522" name="__codelineno-0-522"></a>        <span class="c1"># Preparing the model request</span>
<a id="__codelineno-0-523" name="__codelineno-0-523"></a>        <span class="n">generate_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-0-524" name="__codelineno-0-524"></a>            <span class="n">temp</span><span class="o">=</span><span class="n">temp</span><span class="p">,</span>
<a id="__codelineno-0-525" name="__codelineno-0-525"></a>            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
<a id="__codelineno-0-526" name="__codelineno-0-526"></a>            <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
<a id="__codelineno-0-527" name="__codelineno-0-527"></a>            <span class="n">min_p</span><span class="o">=</span><span class="n">min_p</span><span class="p">,</span>
<a id="__codelineno-0-528" name="__codelineno-0-528"></a>            <span class="n">repeat_penalty</span><span class="o">=</span><span class="n">repeat_penalty</span><span class="p">,</span>
<a id="__codelineno-0-529" name="__codelineno-0-529"></a>            <span class="n">repeat_last_n</span><span class="o">=</span><span class="n">repeat_last_n</span><span class="p">,</span>
<a id="__codelineno-0-530" name="__codelineno-0-530"></a>            <span class="n">n_batch</span><span class="o">=</span><span class="n">n_batch</span><span class="p">,</span>
<a id="__codelineno-0-531" name="__codelineno-0-531"></a>            <span class="n">n_predict</span><span class="o">=</span><span class="n">n_predict</span> <span class="k">if</span> <span class="n">n_predict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_tokens</span><span class="p">,</span>
<a id="__codelineno-0-532" name="__codelineno-0-532"></a>        <span class="p">)</span>
<a id="__codelineno-0-533" name="__codelineno-0-533"></a>
<a id="__codelineno-0-534" name="__codelineno-0-534"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-535" name="__codelineno-0-535"></a>            <span class="c1"># check if there is only one message, i.e. system prompt:</span>
<a id="__codelineno-0-536" name="__codelineno-0-536"></a>            <span class="n">reset</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<a id="__codelineno-0-537" name="__codelineno-0-537"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>
<a id="__codelineno-0-538" name="__codelineno-0-538"></a>
<a id="__codelineno-0-539" name="__codelineno-0-539"></a>            <span class="n">fct_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_chat_prompt_template</span><span class="o">.</span><span class="vm">__func__</span>  <span class="c1"># type: ignore[attr-defined]</span>
<a id="__codelineno-0-540" name="__codelineno-0-540"></a>            <span class="k">if</span> <span class="n">fct_func</span> <span class="ow">is</span> <span class="n">GPT4All</span><span class="o">.</span><span class="n">_format_chat_prompt_template</span><span class="p">:</span>
<a id="__codelineno-0-541" name="__codelineno-0-541"></a>                <span class="k">if</span> <span class="n">reset</span><span class="p">:</span>
<a id="__codelineno-0-542" name="__codelineno-0-542"></a>                    <span class="c1"># ingest system prompt</span>
<a id="__codelineno-0-543" name="__codelineno-0-543"></a>                    <span class="c1"># use "%1%2" and not "%1" to avoid implicit whitespace</span>
<a id="__codelineno-0-544" name="__codelineno-0-544"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">"content"</span><span class="p">],</span> <span class="s2">"</span><span class="si">%1%</span><span class="s2">2"</span><span class="p">,</span>
<a id="__codelineno-0-545" name="__codelineno-0-545"></a>                                            <span class="n">empty_response_callback</span><span class="p">,</span>
<a id="__codelineno-0-546" name="__codelineno-0-546"></a>                                            <span class="n">n_batch</span><span class="o">=</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">n_predict</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reset_context</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-547" name="__codelineno-0-547"></a>                <span class="n">prompt_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"%1"</span><span class="p">,</span> <span class="s2">"%2"</span><span class="p">)</span>
<a id="__codelineno-0-548" name="__codelineno-0-548"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-549" name="__codelineno-0-549"></a>                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-550" name="__codelineno-0-550"></a>                    <span class="s2">"_format_chat_prompt_template is deprecated. Please use a chat session with a prompt template."</span><span class="p">,</span>
<a id="__codelineno-0-551" name="__codelineno-0-551"></a>                    <span class="ne">DeprecationWarning</span><span class="p">,</span>
<a id="__codelineno-0-552" name="__codelineno-0-552"></a>                <span class="p">)</span>
<a id="__codelineno-0-553" name="__codelineno-0-553"></a>                <span class="c1"># special tokens won't be processed</span>
<a id="__codelineno-0-554" name="__codelineno-0-554"></a>                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_chat_prompt_template</span><span class="p">(</span>
<a id="__codelineno-0-555" name="__codelineno-0-555"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span>
<a id="__codelineno-0-556" name="__codelineno-0-556"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">"content"</span><span class="p">]</span> <span class="k">if</span> <span class="n">reset</span> <span class="k">else</span> <span class="s2">""</span><span class="p">,</span>
<a id="__codelineno-0-557" name="__codelineno-0-557"></a>                <span class="p">)</span>
<a id="__codelineno-0-558" name="__codelineno-0-558"></a>                <span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">"%1"</span>
<a id="__codelineno-0-559" name="__codelineno-0-559"></a>                <span class="n">generate_kwargs</span><span class="p">[</span><span class="s2">"reset_context"</span><span class="p">]</span> <span class="o">=</span> <span class="n">reset</span>
<a id="__codelineno-0-560" name="__codelineno-0-560"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-561" name="__codelineno-0-561"></a>            <span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">"%1"</span>
<a id="__codelineno-0-562" name="__codelineno-0-562"></a>            <span class="n">generate_kwargs</span><span class="p">[</span><span class="s2">"reset_context"</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-563" name="__codelineno-0-563"></a>
<a id="__codelineno-0-564" name="__codelineno-0-564"></a>        <span class="c1"># Prepare the callback, process the model response</span>
<a id="__codelineno-0-565" name="__codelineno-0-565"></a>        <span class="n">output_collector</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">]</span>
<a id="__codelineno-0-566" name="__codelineno-0-566"></a>        <span class="n">output_collector</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-567" name="__codelineno-0-567"></a>            <span class="p">{</span><span class="s2">"content"</span><span class="p">:</span> <span class="s2">""</span><span class="p">}</span>
<a id="__codelineno-0-568" name="__codelineno-0-568"></a>        <span class="p">]</span>  <span class="c1"># placeholder for the self._history if chat session is not activated</span>
<a id="__codelineno-0-569" name="__codelineno-0-569"></a>
<a id="__codelineno-0-570" name="__codelineno-0-570"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-571" name="__codelineno-0-571"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"assistant"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">""</span><span class="p">})</span>
<a id="__codelineno-0-572" name="__codelineno-0-572"></a>            <span class="n">output_collector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span>
<a id="__codelineno-0-573" name="__codelineno-0-573"></a>
<a id="__codelineno-0-574" name="__codelineno-0-574"></a>        <span class="k">def</span> <span class="nf">_callback_wrapper</span><span class="p">(</span>
<a id="__codelineno-0-575" name="__codelineno-0-575"></a>            <span class="n">callback</span><span class="p">:</span> <span class="n">ResponseCallbackType</span><span class="p">,</span>
<a id="__codelineno-0-576" name="__codelineno-0-576"></a>            <span class="n">output_collector</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">],</span>
<a id="__codelineno-0-577" name="__codelineno-0-577"></a>        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResponseCallbackType</span><span class="p">:</span>
<a id="__codelineno-0-578" name="__codelineno-0-578"></a>            <span class="k">def</span> <span class="nf">_callback</span><span class="p">(</span><span class="n">token_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-579" name="__codelineno-0-579"></a>                <span class="k">nonlocal</span> <span class="n">callback</span><span class="p">,</span> <span class="n">output_collector</span>
<a id="__codelineno-0-580" name="__codelineno-0-580"></a>
<a id="__codelineno-0-581" name="__codelineno-0-581"></a>                <span class="n">output_collector</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s2">"content"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">response</span>
<a id="__codelineno-0-582" name="__codelineno-0-582"></a>
<a id="__codelineno-0-583" name="__codelineno-0-583"></a>                <span class="k">return</span> <span class="n">callback</span><span class="p">(</span><span class="n">token_id</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>
<a id="__codelineno-0-584" name="__codelineno-0-584"></a>
<a id="__codelineno-0-585" name="__codelineno-0-585"></a>            <span class="k">return</span> <span class="n">_callback</span>
<a id="__codelineno-0-586" name="__codelineno-0-586"></a>
<a id="__codelineno-0-587" name="__codelineno-0-587"></a>        <span class="c1"># Send the request to the model</span>
<a id="__codelineno-0-588" name="__codelineno-0-588"></a>        <span class="k">if</span> <span class="n">streaming</span><span class="p">:</span>
<a id="__codelineno-0-589" name="__codelineno-0-589"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_model_streaming</span><span class="p">(</span>
<a id="__codelineno-0-590" name="__codelineno-0-590"></a>                <span class="n">prompt</span><span class="p">,</span>
<a id="__codelineno-0-591" name="__codelineno-0-591"></a>                <span class="n">prompt_template</span><span class="p">,</span>
<a id="__codelineno-0-592" name="__codelineno-0-592"></a>                <span class="n">_callback_wrapper</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">output_collector</span><span class="p">),</span>
<a id="__codelineno-0-593" name="__codelineno-0-593"></a>                <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-594" name="__codelineno-0-594"></a>            <span class="p">)</span>
<a id="__codelineno-0-595" name="__codelineno-0-595"></a>
<a id="__codelineno-0-596" name="__codelineno-0-596"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_model</span><span class="p">(</span>
<a id="__codelineno-0-597" name="__codelineno-0-597"></a>            <span class="n">prompt</span><span class="p">,</span>
<a id="__codelineno-0-598" name="__codelineno-0-598"></a>            <span class="n">prompt_template</span><span class="p">,</span>
<a id="__codelineno-0-599" name="__codelineno-0-599"></a>            <span class="n">_callback_wrapper</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">output_collector</span><span class="p">),</span>
<a id="__codelineno-0-600" name="__codelineno-0-600"></a>            <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-601" name="__codelineno-0-601"></a>        <span class="p">)</span>
<a id="__codelineno-0-602" name="__codelineno-0-602"></a>
<a id="__codelineno-0-603" name="__codelineno-0-603"></a>        <span class="k">return</span> <span class="n">output_collector</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s2">"content"</span><span class="p">]</span>
<a id="__codelineno-0-604" name="__codelineno-0-604"></a>
<a id="__codelineno-0-605" name="__codelineno-0-605"></a>    <span class="nd">@contextmanager</span>
<a id="__codelineno-0-606" name="__codelineno-0-606"></a>    <span class="k">def</span> <span class="nf">chat_session</span><span class="p">(</span>
<a id="__codelineno-0-607" name="__codelineno-0-607"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-608" name="__codelineno-0-608"></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-609" name="__codelineno-0-609"></a>        <span class="n">prompt_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-610" name="__codelineno-0-610"></a>    <span class="p">):</span>
<a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">        Context manager to hold an inference optimized chat session with a GPT4All model.</span>
<a id="__codelineno-0-613" name="__codelineno-0-613"></a>
<a id="__codelineno-0-614" name="__codelineno-0-614"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">            system_prompt: An initial instruction for the model.</span>
<a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="sd">            prompt_template: Template for the prompts with {0} being replaced by the user message.</span>
<a id="__codelineno-0-617" name="__codelineno-0-617"></a><span class="sd">        """</span>
<a id="__codelineno-0-618" name="__codelineno-0-618"></a>
<a id="__codelineno-0-619" name="__codelineno-0-619"></a>        <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-620" name="__codelineno-0-620"></a>            <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"systemPrompt"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
<a id="__codelineno-0-621" name="__codelineno-0-621"></a>
<a id="__codelineno-0-622" name="__codelineno-0-622"></a>        <span class="k">if</span> <span class="n">prompt_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-623" name="__codelineno-0-623"></a>            <span class="k">if</span> <span class="p">(</span><span class="n">tmpl</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"promptTemplate"</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-624" name="__codelineno-0-624"></a>                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">"Use of a sideloaded model or allow_download=False without specifying a prompt template "</span>
<a id="__codelineno-0-625" name="__codelineno-0-625"></a>                              <span class="s2">"is deprecated. Defaulting to Alpaca."</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
<a id="__codelineno-0-626" name="__codelineno-0-626"></a>                <span class="n">tmpl</span> <span class="o">=</span> <span class="n">DEFAULT_PROMPT_TEMPLATE</span>
<a id="__codelineno-0-627" name="__codelineno-0-627"></a>            <span class="n">prompt_template</span> <span class="o">=</span> <span class="n">tmpl</span>
<a id="__codelineno-0-628" name="__codelineno-0-628"></a>
<a id="__codelineno-0-629" name="__codelineno-0-629"></a>        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"%1(?![0-9])"</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">):</span>
<a id="__codelineno-0-630" name="__codelineno-0-630"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Prompt template containing a literal '%1' is not supported. For a prompt "</span>
<a id="__codelineno-0-631" name="__codelineno-0-631"></a>                             <span class="s2">"placeholder, please use '</span><span class="si">{0}</span><span class="s2">' instead."</span><span class="p">)</span>
<a id="__codelineno-0-632" name="__codelineno-0-632"></a>
<a id="__codelineno-0-633" name="__codelineno-0-633"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"system"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">}]</span>
<a id="__codelineno-0-634" name="__codelineno-0-634"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
<a id="__codelineno-0-635" name="__codelineno-0-635"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-636" name="__codelineno-0-636"></a>            <span class="k">yield</span> <span class="bp">self</span>
<a id="__codelineno-0-637" name="__codelineno-0-637"></a>        <span class="k">finally</span><span class="p">:</span>
<a id="__codelineno-0-638" name="__codelineno-0-638"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-639" name="__codelineno-0-639"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{0}</span><span class="s2">"</span>
<a id="__codelineno-0-640" name="__codelineno-0-640"></a>
<a id="__codelineno-0-641" name="__codelineno-0-641"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-642" name="__codelineno-0-642"></a>    <span class="k">def</span> <span class="nf">list_gpus</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<a id="__codelineno-0-643" name="__codelineno-0-643"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-644" name="__codelineno-0-644"></a><span class="sd">        List the names of the available GPU devices.</span>
<a id="__codelineno-0-645" name="__codelineno-0-645"></a>
<a id="__codelineno-0-646" name="__codelineno-0-646"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-647" name="__codelineno-0-647"></a><span class="sd">            A list of strings representing the names of the available GPU devices.</span>
<a id="__codelineno-0-648" name="__codelineno-0-648"></a><span class="sd">        """</span>
<a id="__codelineno-0-649" name="__codelineno-0-649"></a>        <span class="k">return</span> <span class="n">LLModel</span><span class="o">.</span><span class="n">list_gpus</span><span class="p">()</span>
<a id="__codelineno-0-650" name="__codelineno-0-650"></a>
<a id="__codelineno-0-651" name="__codelineno-0-651"></a>    <span class="k">def</span> <span class="nf">_format_chat_prompt_template</span><span class="p">(</span>
<a id="__codelineno-0-652" name="__codelineno-0-652"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">],</span>
<a id="__codelineno-0-654" name="__codelineno-0-654"></a>        <span class="n">default_prompt_header</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span>
<a id="__codelineno-0-655" name="__codelineno-0-655"></a>        <span class="n">default_prompt_footer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span>
<a id="__codelineno-0-656" name="__codelineno-0-656"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-657" name="__codelineno-0-657"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-658" name="__codelineno-0-658"></a><span class="sd">        Helper method for building a prompt from list of messages using the self._current_prompt_template as a template for each message.</span>
<a id="__codelineno-0-659" name="__codelineno-0-659"></a>
<a id="__codelineno-0-660" name="__codelineno-0-660"></a><span class="sd">        Warning:</span>
<a id="__codelineno-0-661" name="__codelineno-0-661"></a><span class="sd">            This function was deprecated in version 2.3.0, and will be removed in a future release.</span>
<a id="__codelineno-0-662" name="__codelineno-0-662"></a>
<a id="__codelineno-0-663" name="__codelineno-0-663"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-664" name="__codelineno-0-664"></a><span class="sd">            messages:  List of dictionaries. Each dictionary should have a "role" key</span>
<a id="__codelineno-0-665" name="__codelineno-0-665"></a><span class="sd">                with value of "system", "assistant", or "user" and a "content" key with a</span>
<a id="__codelineno-0-666" name="__codelineno-0-666"></a><span class="sd">                string value. Messages are organized such that "system" messages are at top of prompt,</span>
<a id="__codelineno-0-667" name="__codelineno-0-667"></a><span class="sd">                and "user" and "assistant" messages are displayed in order. Assistant messages get formatted as</span>
<a id="__codelineno-0-668" name="__codelineno-0-668"></a><span class="sd">                "Response: {content}".</span>
<a id="__codelineno-0-669" name="__codelineno-0-669"></a>
<a id="__codelineno-0-670" name="__codelineno-0-670"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-671" name="__codelineno-0-671"></a><span class="sd">            Formatted prompt.</span>
<a id="__codelineno-0-672" name="__codelineno-0-672"></a><span class="sd">        """</span>
<a id="__codelineno-0-673" name="__codelineno-0-673"></a>
<a id="__codelineno-0-674" name="__codelineno-0-674"></a>        <span class="n">full_prompt</span> <span class="o">=</span> <span class="n">default_prompt_header</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span> <span class="k">if</span> <span class="n">default_prompt_header</span> <span class="o">!=</span> <span class="s2">""</span> <span class="k">else</span> <span class="s2">""</span>
<a id="__codelineno-0-675" name="__codelineno-0-675"></a>
<a id="__codelineno-0-676" name="__codelineno-0-676"></a>        <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">:</span>
<a id="__codelineno-0-677" name="__codelineno-0-677"></a>            <span class="k">if</span> <span class="n">message</span><span class="p">[</span><span class="s2">"role"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"user"</span><span class="p">:</span>
<a id="__codelineno-0-678" name="__codelineno-0-678"></a>                <span class="n">user_message</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">message</span><span class="p">[</span><span class="s2">"content"</span><span class="p">])</span>
<a id="__codelineno-0-679" name="__codelineno-0-679"></a>                <span class="n">full_prompt</span> <span class="o">+=</span> <span class="n">user_message</span>
<a id="__codelineno-0-680" name="__codelineno-0-680"></a>            <span class="k">if</span> <span class="n">message</span><span class="p">[</span><span class="s2">"role"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"assistant"</span><span class="p">:</span>
<a id="__codelineno-0-681" name="__codelineno-0-681"></a>                <span class="n">assistant_message</span> <span class="o">=</span> <span class="n">message</span><span class="p">[</span><span class="s2">"content"</span><span class="p">]</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>
<a id="__codelineno-0-682" name="__codelineno-0-682"></a>                <span class="n">full_prompt</span> <span class="o">+=</span> <span class="n">assistant_message</span>
<a id="__codelineno-0-683" name="__codelineno-0-683"></a>
<a id="__codelineno-0-684" name="__codelineno-0-684"></a>        <span class="n">full_prompt</span> <span class="o">+=</span> <span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span> <span class="o">+</span> <span class="n">default_prompt_footer</span> <span class="k">if</span> <span class="n">default_prompt_footer</span> <span class="o">!=</span> <span class="s2">""</span> <span class="k">else</span> <span class="s2">""</span>
<a id="__codelineno-0-685" name="__codelineno-0-685"></a>
<a id="__codelineno-0-686" name="__codelineno-0-686"></a>        <span class="k">return</span> <span class="n">full_prompt</span>
</code></pre></div></td></tr></tbody></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h5 id="gpt4all.gpt4all.GPT4All.backend" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">backend</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s1">'cpu'</span><span class="p">,</span> <span class="s1">'kompute'</span><span class="p">,</span> <span class="s1">'cuda'</span><span class="p">,</span> <span class="s1">'metal'</span><span class="p">]</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>The name of the llama.cpp backend currently in use. One of "cpu", "kompute", "cuda", or "metal".</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="gpt4all.gpt4all.GPT4All.device" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>The name of the GPU device currently in use, or None for backends other than Kompute or CUDA.</p>
    </div>

</div>



<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">allow_download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_ctx</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">ngl</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code>model_name</code></b>
              (<code>str</code>)
          
          <div class="doc-md-description">
            <p>Name of GPT4All or custom model. Including ".gguf" file extension is optional but encouraged.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>model_path</code></b>
              (<code>str | <span title="os.PathLike">PathLike</span>[str] | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>Path to directory containing model file or, if file does not exist, where to download model.
Default is None, in which case models will be stored in <code>~/.cache/gpt4all/</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>model_type</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>Model architecture. This argument currently does not have any functionality and is just used as
descriptive identifier for user. Default is None.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>allow_download</code></b>
              (<code>bool</code>, default:
                  <code>True</code>
)
          
          <div class="doc-md-description">
            <p>Allow API to download models from gpt4all.io. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>n_threads</code></b>
              (<code>int | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>number of CPU threads used by GPT4All. Default is None, then the number of threads are determined automatically.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>device</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>The processing unit on which the GPT4All model will run. It can be set to:
- "cpu": Model will run on the central processing unit.
- "gpu": Use Metal on ARM64 macOS, otherwise the same as "kompute".
- "kompute": Use the best GPU provided by the Kompute backend.
- "cuda": Use the best GPU provided by the CUDA backend.
- "amd", "nvidia": Use the best GPU provided by the Kompute backend from this vendor.
- A specific device name from the list returned by <code>GPT4All.list_gpus()</code>.
Default is Metal on ARM64 macOS, "cpu" otherwise.</p>
<p>Note: If a selected GPU device does not have sufficient RAM to accommodate the model, an error will be thrown, and the GPT4All instance will be rendered invalid. It's advised to ensure the device has enough memory before initiating the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>n_ctx</code></b>
              (<code>int</code>, default:
                  <code>2048</code>
)
          
          <div class="doc-md-description">
            <p>Maximum size of context window</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>ngl</code></b>
              (<code>int</code>, default:
                  <code>100</code>
)
          
          <div class="doc-md-description">
            <p>Number of GPU layers to use (Vulkan)</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>verbose</code></b>
              (<code>bool</code>, default:
                  <code>False</code>
)
          
          <div class="doc-md-description">
            <p>If True, print debug messages.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-168">168</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-169">169</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-170">170</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-171">171</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-172">172</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-173">173</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-174">174</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-175">175</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-176">176</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-177">177</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-178">178</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-179">179</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-180">180</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-181">181</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-182">182</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-183">183</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-184">184</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-185">185</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-186">186</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-187">187</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-188">188</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-189">189</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-190">190</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-191">191</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-192">192</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-193">193</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-194">194</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-195">195</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-196">196</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-197">197</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-198">198</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-199">199</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-200">200</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-201">201</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-202">202</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-203">203</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-204">204</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-205">205</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-206">206</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-207">207</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-208">208</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-209">209</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-210">210</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-211">211</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-212">212</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-213">213</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-214">214</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-215">215</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-216">216</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-217">217</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-218">218</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-219">219</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-220">220</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-221">221</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-222">222</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-223">223</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-224">224</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-225">225</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-226">226</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-227">227</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-228">228</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-229">229</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-230">230</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-231">231</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-232">232</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-233">233</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-234">234</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-235">235</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-236">236</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-237">237</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-238">238</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-239">239</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-240">240</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-241">241</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-242">242</a></span></pre></div></td><td class="code"><div><pre id="__code_21"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_21 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="n">allow_download</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="n">n_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="n">n_ctx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="n">ngl</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="p">):</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">    Constructor</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">        model_name: Name of GPT4All or custom model. Including ".gguf" file extension is optional but encouraged.</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">        model_path: Path to directory containing model file or, if file does not exist, where to download model.</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a><span class="sd">            Default is None, in which case models will be stored in `~/.cache/gpt4all/`.</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a><span class="sd">        model_type: Model architecture. This argument currently does not have any functionality and is just used as</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a><span class="sd">            descriptive identifier for user. Default is None.</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="sd">        allow_download: Allow API to download models from gpt4all.io. Default is True.</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="sd">        n_threads: number of CPU threads used by GPT4All. Default is None, then the number of threads are determined automatically.</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">        device: The processing unit on which the GPT4All model will run. It can be set to:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">            - "cpu": Model will run on the central processing unit.</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">            - "gpu": Use Metal on ARM64 macOS, otherwise the same as "kompute".</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">            - "kompute": Use the best GPU provided by the Kompute backend.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">            - "cuda": Use the best GPU provided by the CUDA backend.</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">            - "amd", "nvidia": Use the best GPU provided by the Kompute backend from this vendor.</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">            - A specific device name from the list returned by `GPT4All.list_gpus()`.</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">            Default is Metal on ARM64 macOS, "cpu" otherwise.</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">            Note: If a selected GPU device does not have sufficient RAM to accommodate the model, an error will be thrown, and the GPT4All instance will be rendered invalid. It's advised to ensure the device has enough memory before initiating the model.</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">        n_ctx: Maximum size of context window</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a><span class="sd">        ngl: Number of GPU layers to use (Vulkan)</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="sd">        verbose: If True, print debug messages.</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a><span class="sd">    """</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="n">model_type</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{0}</span><span class="s2">"</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>    <span class="n">device_init</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>    <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">"darwin"</span><span class="p">:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">"auto"</span>  <span class="c1"># "auto" is effectively "metal" due to currently non-functional fallback</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>        <span class="k">elif</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">"cpu"</span><span class="p">:</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">"cpu"</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>            <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">machine</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">"arm64"</span> <span class="ow">or</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"gpu"</span><span class="p">:</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unknown device for this platform: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">"metal"</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>        <span class="n">backend</span> <span class="o">=</span> <span class="s2">"kompute"</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">"cpu"</span><span class="p">:</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>            <span class="k">pass</span>  <span class="c1"># use kompute with no device</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="k">elif</span> <span class="n">device</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="s2">"kompute"</span><span class="p">):</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>            <span class="n">backend</span> <span class="o">=</span> <span class="n">device</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>            <span class="n">device_init</span> <span class="o">=</span> <span class="s2">"gpu"</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>        <span class="k">elif</span> <span class="n">device</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"cuda:"</span><span class="p">):</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">"cuda"</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>            <span class="n">device_init</span> <span class="o">=</span> <span class="n">_remove_prefix</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="s2">"cuda:"</span><span class="p">)</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>            <span class="n">device_init</span> <span class="o">=</span> <span class="n">_remove_prefix</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="s2">"kompute:"</span><span class="p">)</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>    <span class="c1"># Retrieve model and download if allowed</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> <span class="n">ConfigType</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">retrieve_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span> <span class="n">allow_download</span><span class="o">=</span><span class="n">allow_download</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">LLModel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"path"</span><span class="p">],</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="n">ngl</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>    <span class="k">if</span> <span class="n">device_init</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_gpu</span><span class="p">(</span><span class="n">device_init</span><span class="p">)</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>    <span class="c1"># Set n_threads</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="k">if</span> <span class="n">n_threads</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_thread_count</span><span class="p">(</span><span class="n">n_threads</span><span class="p">)</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.chat_session" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">chat_session</span><span class="p">(</span><span class="n">system_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_template</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Context manager to hold an inference optimized chat session with a GPT4All model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code>system_prompt</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>An initial instruction for the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>prompt_template</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>Template for the prompts with {0} being replaced by the user message.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-605">605</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-606">606</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-607">607</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-608">608</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-609">609</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-610">610</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-611">611</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-612">612</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-613">613</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-614">614</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-615">615</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-616">616</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-617">617</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-618">618</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-619">619</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-620">620</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-621">621</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-622">622</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-623">623</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-624">624</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-625">625</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-626">626</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-627">627</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-628">628</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-629">629</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-630">630</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-631">631</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-632">632</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-633">633</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-634">634</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-635">635</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-636">636</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-637">637</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-638">638</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-639">639</a></span></pre></div></td><td class="code"><div><pre id="__code_22"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_22 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-605" name="__codelineno-0-605"></a><span class="nd">@contextmanager</span>
<a id="__codelineno-0-606" name="__codelineno-0-606"></a><span class="k">def</span> <span class="nf">chat_session</span><span class="p">(</span>
<a id="__codelineno-0-607" name="__codelineno-0-607"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-608" name="__codelineno-0-608"></a>    <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-609" name="__codelineno-0-609"></a>    <span class="n">prompt_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-610" name="__codelineno-0-610"></a><span class="p">):</span>
<a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">    Context manager to hold an inference optimized chat session with a GPT4All model.</span>
<a id="__codelineno-0-613" name="__codelineno-0-613"></a>
<a id="__codelineno-0-614" name="__codelineno-0-614"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">        system_prompt: An initial instruction for the model.</span>
<a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="sd">        prompt_template: Template for the prompts with {0} being replaced by the user message.</span>
<a id="__codelineno-0-617" name="__codelineno-0-617"></a><span class="sd">    """</span>
<a id="__codelineno-0-618" name="__codelineno-0-618"></a>
<a id="__codelineno-0-619" name="__codelineno-0-619"></a>    <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-620" name="__codelineno-0-620"></a>        <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"systemPrompt"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
<a id="__codelineno-0-621" name="__codelineno-0-621"></a>
<a id="__codelineno-0-622" name="__codelineno-0-622"></a>    <span class="k">if</span> <span class="n">prompt_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-623" name="__codelineno-0-623"></a>        <span class="k">if</span> <span class="p">(</span><span class="n">tmpl</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"promptTemplate"</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-624" name="__codelineno-0-624"></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">"Use of a sideloaded model or allow_download=False without specifying a prompt template "</span>
<a id="__codelineno-0-625" name="__codelineno-0-625"></a>                          <span class="s2">"is deprecated. Defaulting to Alpaca."</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
<a id="__codelineno-0-626" name="__codelineno-0-626"></a>            <span class="n">tmpl</span> <span class="o">=</span> <span class="n">DEFAULT_PROMPT_TEMPLATE</span>
<a id="__codelineno-0-627" name="__codelineno-0-627"></a>        <span class="n">prompt_template</span> <span class="o">=</span> <span class="n">tmpl</span>
<a id="__codelineno-0-628" name="__codelineno-0-628"></a>
<a id="__codelineno-0-629" name="__codelineno-0-629"></a>    <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"%1(?![0-9])"</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">):</span>
<a id="__codelineno-0-630" name="__codelineno-0-630"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Prompt template containing a literal '%1' is not supported. For a prompt "</span>
<a id="__codelineno-0-631" name="__codelineno-0-631"></a>                         <span class="s2">"placeholder, please use '</span><span class="si">{0}</span><span class="s2">' instead."</span><span class="p">)</span>
<a id="__codelineno-0-632" name="__codelineno-0-632"></a>
<a id="__codelineno-0-633" name="__codelineno-0-633"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"system"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">}]</span>
<a id="__codelineno-0-634" name="__codelineno-0-634"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
<a id="__codelineno-0-635" name="__codelineno-0-635"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-636" name="__codelineno-0-636"></a>        <span class="k">yield</span> <span class="bp">self</span>
<a id="__codelineno-0-637" name="__codelineno-0-637"></a>    <span class="k">finally</span><span class="p">:</span>
<a id="__codelineno-0-638" name="__codelineno-0-638"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-639" name="__codelineno-0-639"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{0}</span><span class="s2">"</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.close" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">close</span><span class="p">()</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Delete the model instance and free associated system resources.</p>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-252">252</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-253">253</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-254">254</a></span></pre></div></td><td class="code"><div><pre id="__code_23"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_23 &gt; code"></button><code><a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="w">    </span><span class="sd">"""Delete the model instance and free associated system resources."""</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.download_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">download_model</span><span class="p">(</span><span class="n">model_filename</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">expected_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">expected_md5</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Download model from gpt4all.io.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code>model_filename</code></b>
              (<code>str</code>)
          
          <div class="doc-md-description">
            <p>Filename of model (with .gguf extension).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>model_path</code></b>
              (<code>str | <span title="os.PathLike">PathLike</span>[str]</code>)
          
          <div class="doc-md-description">
            <p>Path to download model to.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>verbose</code></b>
              (<code>bool</code>, default:
                  <code>True</code>
)
          
          <div class="doc-md-description">
            <p>If True (default), print debug messages.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>url</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>the models remote url (e.g. may be hosted on HF)</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>expected_size</code></b>
              (<code>int | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>The expected size of the download.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>expected_md5</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>The expected MD5 hash of the download.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code>str | <span title="os.PathLike">PathLike</span>[str]</code>
          
          <div class="doc-md-description">
            <p>Model file destination.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-350">350</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-351">351</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-352">352</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-353">353</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-354">354</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-355">355</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-356">356</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-357">357</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-358">358</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-359">359</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-360">360</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-361">361</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-362">362</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-363">363</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-364">364</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-365">365</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-366">366</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-367">367</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-368">368</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-369">369</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-370">370</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-371">371</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-372">372</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-373">373</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-374">374</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-375">375</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-376">376</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-377">377</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-378">378</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-379">379</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-380">380</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-381">381</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-382">382</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-383">383</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-384">384</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-385">385</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-386">386</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-387">387</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-388">388</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-389">389</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-390">390</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-391">391</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-392">392</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-393">393</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-394">394</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-395">395</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-396">396</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-397">397</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-398">398</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-399">399</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-400">400</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-401">401</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-402">402</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-403">403</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-404">404</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-405">405</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-406">406</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-407">407</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-408">408</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-409">409</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-410">410</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-411">411</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-412">412</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-413">413</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-414">414</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-415">415</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-416">416</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-417">417</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-418">418</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-419">419</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-420">420</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-421">421</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-422">422</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-423">423</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-424">424</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-425">425</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-426">426</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-427">427</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-428">428</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-429">429</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-430">430</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-431">431</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-432">432</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-433">433</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-434">434</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-435">435</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-436">436</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-437">437</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-438">438</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-439">439</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-440">440</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-441">441</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-442">442</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-443">443</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-444">444</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-445">445</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-446">446</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-447">447</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-448">448</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-449">449</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-450">450</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-451">451</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-452">452</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-453">453</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-454">454</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-455">455</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-456">456</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-457">457</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-458">458</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-459">459</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-460">460</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-461">461</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-462">462</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-463">463</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-464">464</a></span></pre></div></td><td class="code"><div><pre id="__code_24"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_24 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-350" name="__codelineno-0-350"></a><span class="nd">@staticmethod</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a><span class="k">def</span> <span class="nf">download_model</span><span class="p">(</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>    <span class="n">model_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>    <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>    <span class="n">url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>    <span class="n">expected_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>    <span class="n">expected_md5</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="sd">    Download model from gpt4all.io.</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a><span class="sd">        model_filename: Filename of model (with .gguf extension).</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a><span class="sd">        model_path: Path to download model to.</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a><span class="sd">        verbose: If True (default), print debug messages.</span>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a><span class="sd">        url: the models remote url (e.g. may be hosted on HF)</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a><span class="sd">        expected_size: The expected size of the download.</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a><span class="sd">        expected_md5: The expected MD5 hash of the download.</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="sd">        Model file destination.</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a><span class="sd">    """</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>    <span class="c1"># Download model</span>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>    <span class="k">if</span> <span class="n">url</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>        <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"https://gpt4all.io/models/gguf/</span><span class="si">{</span><span class="n">model_filename</span><span class="si">}</span><span class="s2">"</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>    <span class="k">def</span> <span class="nf">make_request</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>        <span class="n">headers</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a>        <span class="k">if</span> <span class="n">offset</span><span class="p">:</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Download interrupted, resuming from byte position </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>            <span class="n">headers</span><span class="p">[</span><span class="s1">'Range'</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'bytes=</span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s1">-'</span>  <span class="c1"># resume incomplete response</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a>            <span class="n">headers</span><span class="p">[</span><span class="s2">"Accept-Encoding"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"identity"</span>  <span class="c1"># Content-Encoding changes meaning of ranges</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a>        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a>        <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">206</span><span class="p">):</span>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Request failed: HTTP </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">reason</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a>        <span class="k">if</span> <span class="n">offset</span> <span class="ow">and</span> <span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">206</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'Content-Range'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)):</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Connection was interrupted and server does not support range requests'</span><span class="p">)</span>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a>        <span class="k">if</span> <span class="p">(</span><span class="n">enc</span> <span class="o">:=</span> <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"Content-Encoding"</span><span class="p">))</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected identity Content-Encoding, got </span><span class="si">{</span><span class="n">enc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a>        <span class="k">return</span> <span class="n">response</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>    <span class="n">response</span> <span class="o">=</span> <span class="n">make_request</span><span class="p">()</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>    <span class="n">total_size_in_bytes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"content-length"</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>    <span class="n">block_size</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>  <span class="c1"># 1 MB</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>    <span class="n">partial_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">model_filename</span> <span class="o">+</span> <span class="s2">".part"</span><span class="p">)</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">partial_path</span><span class="p">,</span> <span class="s2">"w+b"</span><span class="p">)</span> <span class="k">as</span> <span class="n">partf</span><span class="p">:</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a>            <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s2">"Downloading"</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">total_size_in_bytes</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">"iB"</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress_bar</span><span class="p">:</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>                <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>                    <span class="n">last_progress</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>                    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>                        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">block_size</span><span class="p">):</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>                            <span class="n">partf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>                            <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>                    <span class="k">except</span> <span class="n">ChunkedEncodingError</span> <span class="k">as</span> <span class="n">cee</span><span class="p">:</span>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a>                        <span class="k">if</span> <span class="n">cee</span><span class="o">.</span><span class="n">args</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pe</span> <span class="o">:=</span> <span class="n">cee</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ProtocolError</span><span class="p">):</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>                            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pe</span><span class="o">.</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ir</span> <span class="o">:=</span> <span class="n">pe</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">IncompleteRead</span><span class="p">):</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>                                <span class="k">assert</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">&lt;=</span> <span class="n">ir</span><span class="o">.</span><span class="n">partial</span>  <span class="c1"># urllib3 may be ahead of us but never behind</span>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a>                                <span class="c1"># the socket was closed during a read - retry</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a>                                <span class="n">response</span> <span class="o">=</span> <span class="n">make_request</span><span class="p">(</span><span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a>                                <span class="k">continue</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a>                        <span class="k">raise</span>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>                    <span class="k">if</span> <span class="n">total_size_in_bytes</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">&lt;</span> <span class="n">total_size_in_bytes</span><span class="p">:</span>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>                        <span class="k">if</span> <span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">==</span> <span class="n">last_progress</span><span class="p">:</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"Download not making progress, aborting."</span><span class="p">)</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>                        <span class="c1"># server closed connection prematurely - retry</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>                        <span class="n">response</span> <span class="o">=</span> <span class="n">make_request</span><span class="p">(</span><span class="n">progress_bar</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>                        <span class="k">continue</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>                    <span class="k">break</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>            <span class="c1"># verify file integrity</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>            <span class="n">file_size</span> <span class="o">=</span> <span class="n">partf</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>            <span class="k">if</span> <span class="n">expected_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">file_size</span> <span class="o">!=</span> <span class="n">expected_size</span><span class="p">:</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected file size of </span><span class="si">{</span><span class="n">expected_size</span><span class="si">}</span><span class="s2"> bytes, got </span><span class="si">{</span><span class="n">file_size</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>            <span class="k">if</span> <span class="n">expected_md5</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>                <span class="n">partf</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>                <span class="n">hsh</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">()</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>                <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s2">"Verifying"</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">file_size</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">"iB"</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">bar</span><span class="p">:</span>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>                    <span class="k">while</span> <span class="n">chunk</span> <span class="o">:=</span> <span class="n">partf</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">block_size</span><span class="p">):</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>                        <span class="n">hsh</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>                        <span class="n">bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">))</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>                <span class="k">if</span> <span class="n">hsh</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span> <span class="o">!=</span> <span class="n">expected_md5</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected MD5 hash of </span><span class="si">{</span><span class="n">expected_md5</span><span class="si">!r}</span><span class="s2">, got </span><span class="si">{</span><span class="n">hsh</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a>        <span class="k">except</span><span class="p">:</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a>            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">"Cleaning up the interrupted download..."</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">partial_path</span><span class="p">)</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>            <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a>                <span class="k">pass</span>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a>            <span class="k">raise</span>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a>        <span class="c1"># flush buffers and sync the inode</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>        <span class="n">partf</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a>        <span class="n">_fsync</span><span class="p">(</span><span class="n">partf</span><span class="p">)</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a>    <span class="c1"># move to final destination</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a>    <span class="n">download_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span> <span class="o">/</span> <span class="n">model_filename</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a>        <span class="n">os</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">partial_path</span><span class="p">,</span> <span class="n">download_path</span><span class="p">)</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>    <span class="k">except</span> <span class="ne">FileExistsError</span><span class="p">:</span>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a>            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">partial_path</span><span class="p">)</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a>        <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a>            <span class="k">pass</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>        <span class="k">raise</span>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model downloaded to </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">download_path</span><span class="p">)</span><span class="si">!r}</span><span class="s2">"</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>    <span class="k">return</span> <span class="n">download_path</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.generate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">temp</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">min_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">repeat_penalty</span><span class="o">=</span><span class="mf">1.18</span><span class="p">,</span> <span class="n">repeat_last_n</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_batch</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_predict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">streaming</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">empty_response_callback</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Generate outputs from any GPT4All model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code>prompt</code></b>
              (<code>str</code>)
          
          <div class="doc-md-description">
            <p>The prompt for the model to complete.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>max_tokens</code></b>
              (<code>int</code>, default:
                  <code>200</code>
)
          
          <div class="doc-md-description">
            <p>The maximum number of tokens to generate.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>temp</code></b>
              (<code>float</code>, default:
                  <code>0.7</code>
)
          
          <div class="doc-md-description">
            <p>The model temperature. Larger values increase creativity but decrease factuality.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>top_k</code></b>
              (<code>int</code>, default:
                  <code>40</code>
)
          
          <div class="doc-md-description">
            <p>Randomly sample from the top_k most likely tokens at each generation step. Set this to 1 for greedy decoding.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>top_p</code></b>
              (<code>float</code>, default:
                  <code>0.4</code>
)
          
          <div class="doc-md-description">
            <p>Randomly sample at each generation step from the top most likely tokens whose probabilities add up to top_p.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>min_p</code></b>
              (<code>float</code>, default:
                  <code>0.0</code>
)
          
          <div class="doc-md-description">
            <p>Randomly sample at each generation step from the top most likely tokens whose probabilities are at least min_p.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>repeat_penalty</code></b>
              (<code>float</code>, default:
                  <code>1.18</code>
)
          
          <div class="doc-md-description">
            <p>Penalize the model for repetition. Higher values result in less repetition.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>repeat_last_n</code></b>
              (<code>int</code>, default:
                  <code>64</code>
)
          
          <div class="doc-md-description">
            <p>How far in the models generation history to apply the repeat penalty.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>n_batch</code></b>
              (<code>int</code>, default:
                  <code>8</code>
)
          
          <div class="doc-md-description">
            <p>Number of prompt tokens processed in parallel. Larger values decrease latency but increase resource requirements.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>n_predict</code></b>
              (<code>int | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>Equivalent to max_tokens, exists for backwards compatibility.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>streaming</code></b>
              (<code>bool</code>, default:
                  <code>False</code>
)
          
          <div class="doc-md-description">
            <p>If True, this method will instead return a generator that yields tokens as the model generates them.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>callback</code></b>
              (<code><span title="gpt4all._pyllmodel.ResponseCallbackType">ResponseCallbackType</span></code>, default:
                  <code><span title="gpt4all._pyllmodel.empty_response_callback">empty_response_callback</span></code>
)
          
          <div class="doc-md-description">
            <p>A function with arguments token_id:int and response:str, which receives the tokens from the model as they are generated and stops the generation by returning False.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><span title="typing.Any">Any</span></code>
          
          <div class="doc-md-description">
            <p>Either the entire completion or a generator that yields the completion token by token.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-485">485</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-486">486</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-487">487</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-488">488</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-489">489</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-490">490</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-491">491</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-492">492</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-493">493</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-494">494</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-495">495</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-496">496</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-497">497</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-498">498</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-499">499</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-500">500</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-501">501</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-502">502</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-503">503</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-504">504</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-505">505</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-506">506</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-507">507</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-508">508</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-509">509</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-510">510</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-511">511</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-512">512</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-513">513</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-514">514</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-515">515</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-516">516</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-517">517</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-518">518</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-519">519</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-520">520</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-521">521</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-522">522</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-523">523</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-524">524</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-525">525</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-526">526</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-527">527</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-528">528</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-529">529</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-530">530</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-531">531</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-532">532</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-533">533</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-534">534</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-535">535</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-536">536</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-537">537</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-538">538</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-539">539</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-540">540</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-541">541</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-542">542</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-543">543</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-544">544</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-545">545</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-546">546</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-547">547</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-548">548</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-549">549</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-550">550</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-551">551</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-552">552</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-553">553</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-554">554</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-555">555</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-556">556</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-557">557</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-558">558</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-559">559</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-560">560</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-561">561</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-562">562</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-563">563</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-564">564</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-565">565</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-566">566</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-567">567</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-568">568</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-569">569</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-570">570</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-571">571</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-572">572</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-573">573</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-574">574</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-575">575</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-576">576</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-577">577</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-578">578</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-579">579</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-580">580</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-581">581</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-582">582</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-583">583</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-584">584</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-585">585</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-586">586</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-587">587</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-588">588</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-589">589</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-590">590</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-591">591</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-592">592</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-593">593</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-594">594</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-595">595</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-596">596</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-597">597</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-598">598</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-599">599</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-600">600</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-601">601</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-602">602</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-603">603</a></span></pre></div></td><td class="code"><div><pre id="__code_25"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_25 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a>    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a>    <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a>    <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a>    <span class="n">top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">40</span><span class="p">,</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a>    <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>    <span class="n">min_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a>    <span class="n">repeat_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.18</span><span class="p">,</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>    <span class="n">repeat_last_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a>    <span class="n">n_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>    <span class="n">n_predict</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a>    <span class="n">streaming</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a>    <span class="n">callback</span><span class="p">:</span> <span class="n">ResponseCallbackType</span> <span class="o">=</span> <span class="n">empty_response_callback</span><span class="p">,</span>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-501" name="__codelineno-0-501"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-502" name="__codelineno-0-502"></a><span class="sd">    Generate outputs from any GPT4All model.</span>
<a id="__codelineno-0-503" name="__codelineno-0-503"></a>
<a id="__codelineno-0-504" name="__codelineno-0-504"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-505" name="__codelineno-0-505"></a><span class="sd">        prompt: The prompt for the model to complete.</span>
<a id="__codelineno-0-506" name="__codelineno-0-506"></a><span class="sd">        max_tokens: The maximum number of tokens to generate.</span>
<a id="__codelineno-0-507" name="__codelineno-0-507"></a><span class="sd">        temp: The model temperature. Larger values increase creativity but decrease factuality.</span>
<a id="__codelineno-0-508" name="__codelineno-0-508"></a><span class="sd">        top_k: Randomly sample from the top_k most likely tokens at each generation step. Set this to 1 for greedy decoding.</span>
<a id="__codelineno-0-509" name="__codelineno-0-509"></a><span class="sd">        top_p: Randomly sample at each generation step from the top most likely tokens whose probabilities add up to top_p.</span>
<a id="__codelineno-0-510" name="__codelineno-0-510"></a><span class="sd">        min_p: Randomly sample at each generation step from the top most likely tokens whose probabilities are at least min_p.</span>
<a id="__codelineno-0-511" name="__codelineno-0-511"></a><span class="sd">        repeat_penalty: Penalize the model for repetition. Higher values result in less repetition.</span>
<a id="__codelineno-0-512" name="__codelineno-0-512"></a><span class="sd">        repeat_last_n: How far in the models generation history to apply the repeat penalty.</span>
<a id="__codelineno-0-513" name="__codelineno-0-513"></a><span class="sd">        n_batch: Number of prompt tokens processed in parallel. Larger values decrease latency but increase resource requirements.</span>
<a id="__codelineno-0-514" name="__codelineno-0-514"></a><span class="sd">        n_predict: Equivalent to max_tokens, exists for backwards compatibility.</span>
<a id="__codelineno-0-515" name="__codelineno-0-515"></a><span class="sd">        streaming: If True, this method will instead return a generator that yields tokens as the model generates them.</span>
<a id="__codelineno-0-516" name="__codelineno-0-516"></a><span class="sd">        callback: A function with arguments token_id:int and response:str, which receives the tokens from the model as they are generated and stops the generation by returning False.</span>
<a id="__codelineno-0-517" name="__codelineno-0-517"></a>
<a id="__codelineno-0-518" name="__codelineno-0-518"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-519" name="__codelineno-0-519"></a><span class="sd">        Either the entire completion or a generator that yields the completion token by token.</span>
<a id="__codelineno-0-520" name="__codelineno-0-520"></a><span class="sd">    """</span>
<a id="__codelineno-0-521" name="__codelineno-0-521"></a>
<a id="__codelineno-0-522" name="__codelineno-0-522"></a>    <span class="c1"># Preparing the model request</span>
<a id="__codelineno-0-523" name="__codelineno-0-523"></a>    <span class="n">generate_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-0-524" name="__codelineno-0-524"></a>        <span class="n">temp</span><span class="o">=</span><span class="n">temp</span><span class="p">,</span>
<a id="__codelineno-0-525" name="__codelineno-0-525"></a>        <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
<a id="__codelineno-0-526" name="__codelineno-0-526"></a>        <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
<a id="__codelineno-0-527" name="__codelineno-0-527"></a>        <span class="n">min_p</span><span class="o">=</span><span class="n">min_p</span><span class="p">,</span>
<a id="__codelineno-0-528" name="__codelineno-0-528"></a>        <span class="n">repeat_penalty</span><span class="o">=</span><span class="n">repeat_penalty</span><span class="p">,</span>
<a id="__codelineno-0-529" name="__codelineno-0-529"></a>        <span class="n">repeat_last_n</span><span class="o">=</span><span class="n">repeat_last_n</span><span class="p">,</span>
<a id="__codelineno-0-530" name="__codelineno-0-530"></a>        <span class="n">n_batch</span><span class="o">=</span><span class="n">n_batch</span><span class="p">,</span>
<a id="__codelineno-0-531" name="__codelineno-0-531"></a>        <span class="n">n_predict</span><span class="o">=</span><span class="n">n_predict</span> <span class="k">if</span> <span class="n">n_predict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_tokens</span><span class="p">,</span>
<a id="__codelineno-0-532" name="__codelineno-0-532"></a>    <span class="p">)</span>
<a id="__codelineno-0-533" name="__codelineno-0-533"></a>
<a id="__codelineno-0-534" name="__codelineno-0-534"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-535" name="__codelineno-0-535"></a>        <span class="c1"># check if there is only one message, i.e. system prompt:</span>
<a id="__codelineno-0-536" name="__codelineno-0-536"></a>        <span class="n">reset</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<a id="__codelineno-0-537" name="__codelineno-0-537"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="n">prompt</span><span class="p">})</span>
<a id="__codelineno-0-538" name="__codelineno-0-538"></a>
<a id="__codelineno-0-539" name="__codelineno-0-539"></a>        <span class="n">fct_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_chat_prompt_template</span><span class="o">.</span><span class="vm">__func__</span>  <span class="c1"># type: ignore[attr-defined]</span>
<a id="__codelineno-0-540" name="__codelineno-0-540"></a>        <span class="k">if</span> <span class="n">fct_func</span> <span class="ow">is</span> <span class="n">GPT4All</span><span class="o">.</span><span class="n">_format_chat_prompt_template</span><span class="p">:</span>
<a id="__codelineno-0-541" name="__codelineno-0-541"></a>            <span class="k">if</span> <span class="n">reset</span><span class="p">:</span>
<a id="__codelineno-0-542" name="__codelineno-0-542"></a>                <span class="c1"># ingest system prompt</span>
<a id="__codelineno-0-543" name="__codelineno-0-543"></a>                <span class="c1"># use "%1%2" and not "%1" to avoid implicit whitespace</span>
<a id="__codelineno-0-544" name="__codelineno-0-544"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">"content"</span><span class="p">],</span> <span class="s2">"</span><span class="si">%1%</span><span class="s2">2"</span><span class="p">,</span>
<a id="__codelineno-0-545" name="__codelineno-0-545"></a>                                        <span class="n">empty_response_callback</span><span class="p">,</span>
<a id="__codelineno-0-546" name="__codelineno-0-546"></a>                                        <span class="n">n_batch</span><span class="o">=</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">n_predict</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reset_context</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-547" name="__codelineno-0-547"></a>            <span class="n">prompt_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"%1"</span><span class="p">,</span> <span class="s2">"%2"</span><span class="p">)</span>
<a id="__codelineno-0-548" name="__codelineno-0-548"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-549" name="__codelineno-0-549"></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-550" name="__codelineno-0-550"></a>                <span class="s2">"_format_chat_prompt_template is deprecated. Please use a chat session with a prompt template."</span><span class="p">,</span>
<a id="__codelineno-0-551" name="__codelineno-0-551"></a>                <span class="ne">DeprecationWarning</span><span class="p">,</span>
<a id="__codelineno-0-552" name="__codelineno-0-552"></a>            <span class="p">)</span>
<a id="__codelineno-0-553" name="__codelineno-0-553"></a>            <span class="c1"># special tokens won't be processed</span>
<a id="__codelineno-0-554" name="__codelineno-0-554"></a>            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_chat_prompt_template</span><span class="p">(</span>
<a id="__codelineno-0-555" name="__codelineno-0-555"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span>
<a id="__codelineno-0-556" name="__codelineno-0-556"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">"content"</span><span class="p">]</span> <span class="k">if</span> <span class="n">reset</span> <span class="k">else</span> <span class="s2">""</span><span class="p">,</span>
<a id="__codelineno-0-557" name="__codelineno-0-557"></a>            <span class="p">)</span>
<a id="__codelineno-0-558" name="__codelineno-0-558"></a>            <span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">"%1"</span>
<a id="__codelineno-0-559" name="__codelineno-0-559"></a>            <span class="n">generate_kwargs</span><span class="p">[</span><span class="s2">"reset_context"</span><span class="p">]</span> <span class="o">=</span> <span class="n">reset</span>
<a id="__codelineno-0-560" name="__codelineno-0-560"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-561" name="__codelineno-0-561"></a>        <span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">"%1"</span>
<a id="__codelineno-0-562" name="__codelineno-0-562"></a>        <span class="n">generate_kwargs</span><span class="p">[</span><span class="s2">"reset_context"</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-563" name="__codelineno-0-563"></a>
<a id="__codelineno-0-564" name="__codelineno-0-564"></a>    <span class="c1"># Prepare the callback, process the model response</span>
<a id="__codelineno-0-565" name="__codelineno-0-565"></a>    <span class="n">output_collector</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">]</span>
<a id="__codelineno-0-566" name="__codelineno-0-566"></a>    <span class="n">output_collector</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-567" name="__codelineno-0-567"></a>        <span class="p">{</span><span class="s2">"content"</span><span class="p">:</span> <span class="s2">""</span><span class="p">}</span>
<a id="__codelineno-0-568" name="__codelineno-0-568"></a>    <span class="p">]</span>  <span class="c1"># placeholder for the self._history if chat session is not activated</span>
<a id="__codelineno-0-569" name="__codelineno-0-569"></a>
<a id="__codelineno-0-570" name="__codelineno-0-570"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-571" name="__codelineno-0-571"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"assistant"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">""</span><span class="p">})</span>
<a id="__codelineno-0-572" name="__codelineno-0-572"></a>        <span class="n">output_collector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span>
<a id="__codelineno-0-573" name="__codelineno-0-573"></a>
<a id="__codelineno-0-574" name="__codelineno-0-574"></a>    <span class="k">def</span> <span class="nf">_callback_wrapper</span><span class="p">(</span>
<a id="__codelineno-0-575" name="__codelineno-0-575"></a>        <span class="n">callback</span><span class="p">:</span> <span class="n">ResponseCallbackType</span><span class="p">,</span>
<a id="__codelineno-0-576" name="__codelineno-0-576"></a>        <span class="n">output_collector</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MessageType</span><span class="p">],</span>
<a id="__codelineno-0-577" name="__codelineno-0-577"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResponseCallbackType</span><span class="p">:</span>
<a id="__codelineno-0-578" name="__codelineno-0-578"></a>        <span class="k">def</span> <span class="nf">_callback</span><span class="p">(</span><span class="n">token_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-579" name="__codelineno-0-579"></a>            <span class="k">nonlocal</span> <span class="n">callback</span><span class="p">,</span> <span class="n">output_collector</span>
<a id="__codelineno-0-580" name="__codelineno-0-580"></a>
<a id="__codelineno-0-581" name="__codelineno-0-581"></a>            <span class="n">output_collector</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s2">"content"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">response</span>
<a id="__codelineno-0-582" name="__codelineno-0-582"></a>
<a id="__codelineno-0-583" name="__codelineno-0-583"></a>            <span class="k">return</span> <span class="n">callback</span><span class="p">(</span><span class="n">token_id</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>
<a id="__codelineno-0-584" name="__codelineno-0-584"></a>
<a id="__codelineno-0-585" name="__codelineno-0-585"></a>        <span class="k">return</span> <span class="n">_callback</span>
<a id="__codelineno-0-586" name="__codelineno-0-586"></a>
<a id="__codelineno-0-587" name="__codelineno-0-587"></a>    <span class="c1"># Send the request to the model</span>
<a id="__codelineno-0-588" name="__codelineno-0-588"></a>    <span class="k">if</span> <span class="n">streaming</span><span class="p">:</span>
<a id="__codelineno-0-589" name="__codelineno-0-589"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_model_streaming</span><span class="p">(</span>
<a id="__codelineno-0-590" name="__codelineno-0-590"></a>            <span class="n">prompt</span><span class="p">,</span>
<a id="__codelineno-0-591" name="__codelineno-0-591"></a>            <span class="n">prompt_template</span><span class="p">,</span>
<a id="__codelineno-0-592" name="__codelineno-0-592"></a>            <span class="n">_callback_wrapper</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">output_collector</span><span class="p">),</span>
<a id="__codelineno-0-593" name="__codelineno-0-593"></a>            <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-594" name="__codelineno-0-594"></a>        <span class="p">)</span>
<a id="__codelineno-0-595" name="__codelineno-0-595"></a>
<a id="__codelineno-0-596" name="__codelineno-0-596"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_model</span><span class="p">(</span>
<a id="__codelineno-0-597" name="__codelineno-0-597"></a>        <span class="n">prompt</span><span class="p">,</span>
<a id="__codelineno-0-598" name="__codelineno-0-598"></a>        <span class="n">prompt_template</span><span class="p">,</span>
<a id="__codelineno-0-599" name="__codelineno-0-599"></a>        <span class="n">_callback_wrapper</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">output_collector</span><span class="p">),</span>
<a id="__codelineno-0-600" name="__codelineno-0-600"></a>        <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-601" name="__codelineno-0-601"></a>    <span class="p">)</span>
<a id="__codelineno-0-602" name="__codelineno-0-602"></a>
<a id="__codelineno-0-603" name="__codelineno-0-603"></a>    <span class="k">return</span> <span class="n">output_collector</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s2">"content"</span><span class="p">]</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.list_gpus" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">list_gpus</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>List the names of the available GPU devices.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code>list[str]</code>
          
          <div class="doc-md-description">
            <p>A list of strings representing the names of the available GPU devices.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-641">641</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-642">642</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-643">643</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-644">644</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-645">645</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-646">646</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-647">647</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-648">648</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-649">649</a></span></pre></div></td><td class="code"><div><pre id="__code_26"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_26 &gt; code"></button><code><a id="__codelineno-0-641" name="__codelineno-0-641"></a><span class="nd">@staticmethod</span>
<a id="__codelineno-0-642" name="__codelineno-0-642"></a><span class="k">def</span> <span class="nf">list_gpus</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<a id="__codelineno-0-643" name="__codelineno-0-643"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-644" name="__codelineno-0-644"></a><span class="sd">    List the names of the available GPU devices.</span>
<a id="__codelineno-0-645" name="__codelineno-0-645"></a>
<a id="__codelineno-0-646" name="__codelineno-0-646"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-647" name="__codelineno-0-647"></a><span class="sd">        A list of strings representing the names of the available GPU devices.</span>
<a id="__codelineno-0-648" name="__codelineno-0-648"></a><span class="sd">    """</span>
<a id="__codelineno-0-649" name="__codelineno-0-649"></a>    <span class="k">return</span> <span class="n">LLModel</span><span class="o">.</span><span class="n">list_gpus</span><span class="p">()</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.list_models" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">list_models</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Fetch model list from https://gpt4all.io/models/models3.json.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code>list[<span title="gpt4all.gpt4all.ConfigType">ConfigType</span>]</code>
          
          <div class="doc-md-description">
            <p>Model list in JSON format.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-270">270</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-271">271</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-272">272</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-273">273</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-274">274</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-275">275</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-276">276</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-277">277</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-278">278</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-279">279</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-280">280</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-281">281</a></span></pre></div></td><td class="code"><div><pre id="__code_27"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_27 &gt; code"></button><code><a id="__codelineno-0-270" name="__codelineno-0-270"></a><span class="nd">@staticmethod</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="k">def</span> <span class="nf">list_models</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ConfigType</span><span class="p">]:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">    Fetch model list from https://gpt4all.io/models/models3.json.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">        Model list in JSON format.</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">    """</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"https://gpt4all.io/models/models3.json"</span><span class="p">)</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>    <span class="k">if</span> <span class="n">resp</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Request failed: HTTP </span><span class="si">{</span><span class="n">resp</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">resp</span><span class="o">.</span><span class="n">reason</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>    <span class="k">return</span> <span class="n">resp</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.GPT4All.retrieve_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">retrieve_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">allow_download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Find model file, and if it doesn't exist, download the model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code>model_name</code></b>
              (<code>str</code>)
          
          <div class="doc-md-description">
            <p>Name of model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>model_path</code></b>
              (<code>str | <span title="os.PathLike">PathLike</span>[str] | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>Path to find model. Default is None in which case path is set to
~/.cache/gpt4all/.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>allow_download</code></b>
              (<code>bool</code>, default:
                  <code>True</code>
)
          
          <div class="doc-md-description">
            <p>Allow API to download model from gpt4all.io. Default is True.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>verbose</code></b>
              (<code>bool</code>, default:
                  <code>False</code>
)
          
          <div class="doc-md-description">
            <p>If True (default), print debug messages.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><span title="gpt4all.gpt4all.ConfigType">ConfigType</span></code>
          
          <div class="doc-md-description">
            <p>Model config.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-283">283</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-284">284</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-285">285</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-286">286</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-287">287</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-288">288</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-289">289</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-290">290</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-291">291</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-292">292</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-293">293</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-294">294</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-295">295</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-296">296</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-297">297</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-298">298</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-299">299</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-300">300</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-301">301</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-302">302</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-303">303</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-304">304</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-305">305</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-306">306</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-307">307</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-308">308</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-309">309</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-310">310</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-311">311</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-312">312</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-313">313</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-314">314</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-315">315</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-316">316</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-317">317</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-318">318</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-319">319</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-320">320</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-321">321</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-322">322</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-323">323</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-324">324</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-325">325</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-326">326</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-327">327</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-328">328</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-329">329</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-330">330</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-331">331</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-332">332</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-333">333</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-334">334</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-335">335</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-336">336</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-337">337</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-338">338</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-339">339</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-340">340</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-341">341</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-342">342</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-343">343</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-344">344</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-345">345</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-346">346</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-347">347</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-348">348</a></span></pre></div></td><td class="code"><div><pre id="__code_28"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_28 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="nd">@classmethod</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="k">def</span> <span class="nf">retrieve_model</span><span class="p">(</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>    <span class="bp">cls</span><span class="p">,</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>    <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>    <span class="n">allow_download</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ConfigType</span><span class="p">:</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">    Find model file, and if it doesn't exist, download the model.</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">        model_name: Name of model.</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">        model_path: Path to find model. Default is None in which case path is set to</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">            ~/.cache/gpt4all/.</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">        allow_download: Allow API to download model from gpt4all.io. Default is True.</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">        verbose: If True (default), print debug messages.</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="sd">        Model config.</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">    """</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a>    <span class="n">model_filename</span> <span class="o">=</span> <span class="n">append_extension_if_missing</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>    <span class="c1"># get the config for the model</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>    <span class="n">config</span><span class="p">:</span> <span class="n">ConfigType</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>    <span class="k">if</span> <span class="n">allow_download</span><span class="p">:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>        <span class="n">available_models</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_models</span><span class="p">()</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">available_models</span><span class="p">:</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>            <span class="k">if</span> <span class="n">model_filename</span> <span class="o">==</span> <span class="n">m</span><span class="p">[</span><span class="s2">"filename"</span><span class="p">]:</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>                <span class="n">tmpl</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"promptTemplate"</span><span class="p">,</span> <span class="n">DEFAULT_PROMPT_TEMPLATE</span><span class="p">)</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>                <span class="c1"># change to Python-style formatting</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>                <span class="n">m</span><span class="p">[</span><span class="s2">"promptTemplate"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmpl</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"%1"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{0}</span><span class="s2">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"%2"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{1}</span><span class="s2">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>                <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>                <span class="k">break</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>    <span class="c1"># Validate download directory</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>    <span class="k">if</span> <span class="n">model_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">DEFAULT_MODEL_DIRECTORY</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>        <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"Failed to create model download directory"</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>        <span class="n">model_path</span> <span class="o">=</span> <span class="n">DEFAULT_MODEL_DIRECTORY</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>        <span class="n">model_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">model_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model directory does not exist: </span><span class="si">{</span><span class="n">model_path</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>    <span class="n">model_dest</span> <span class="o">=</span> <span class="n">model_path</span> <span class="o">/</span> <span class="n">model_filename</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>    <span class="k">if</span> <span class="n">model_dest</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>        <span class="n">config</span><span class="p">[</span><span class="s2">"path"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_dest</span><span class="p">)</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Found model file at </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">model_dest</span><span class="p">)</span><span class="si">!r}</span><span class="s2">"</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>    <span class="k">elif</span> <span class="n">allow_download</span><span class="p">:</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>        <span class="c1"># If model file does not exist, download</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>        <span class="n">filesize</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"filesize"</span><span class="p">)</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>        <span class="n">config</span><span class="p">[</span><span class="s2">"path"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">download_model</span><span class="p">(</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>            <span class="n">model_filename</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"url"</span><span class="p">),</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>            <span class="n">expected_size</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">filesize</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">filesize</span><span class="p">),</span> <span class="n">expected_md5</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"md5sum"</span><span class="p">),</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>        <span class="p">))</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model file does not exist: </span><span class="si">{</span><span class="n">model_dest</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>    <span class="k">return</span> <span class="n">config</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="gpt4all.gpt4all.Embed4All" class="doc doc-heading">
            <code>Embed4All</code>


</h4>


    <div class="doc doc-contents first">


        <p>Python class that handles embeddings for GPT4All.</p>

              <details class="quote">
                <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-100">100</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-101">101</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-102">102</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-103">103</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-104">104</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-105">105</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-106">106</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-107">107</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-108">108</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-109">109</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-110">110</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-111">111</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-112">112</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-113">113</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-114">114</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-115">115</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-116">116</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-117">117</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-118">118</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-119">119</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-120">120</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-121">121</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-122">122</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-123">123</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-124">124</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-125">125</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-126">126</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-127">127</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-128">128</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-129">129</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-130">130</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-131">131</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-132">132</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-133">133</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-134">134</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-135">135</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-136">136</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-137">137</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-138">138</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-139">139</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-140">140</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-141">141</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-142">142</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-143">143</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-144">144</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-145">145</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-146">146</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-147">147</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-148">148</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-149">149</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-150">150</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-151">151</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-152">152</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-153">153</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-154">154</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-155">155</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-156">156</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-157">157</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-158">158</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-159">159</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-160">160</a></span></pre></div></td><td class="code"><div><pre id="__code_29"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_29 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="k">class</span> <span class="nc">Embed4All</span><span class="p">:</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    Python class that handles embeddings for GPT4All.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">    """</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">MIN_DIMENSIONALITY</span> <span class="o">=</span> <span class="mi">64</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        Constructor</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">            n_threads: number of CPU threads used by GPT4All. Default is None, then the number of threads are determined automatically.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">            device: The processing unit on which the embedding model will run. See the `GPT4All` constructor for more info.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">            kwargs: Remaining keyword arguments are passed to the `GPT4All` constructor.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        """</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>            <span class="n">model_name</span> <span class="o">=</span> <span class="s1">'all-MiniLM-L6-v2.gguf2.f16.gguf'</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">gpt4all</span> <span class="o">=</span> <span class="n">GPT4All</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="k">return</span> <span class="bp">self</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">typ</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="ne">BaseException</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="ne">BaseException</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tb</span><span class="p">:</span> <span class="n">TracebackType</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="w">        </span><span class="sd">"""Delete the model instance and free associated system resources."""</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">gpt4all</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="c1"># return_dict=False</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span> <span class="o">...</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span> <span class="o">...</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">return_dict</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span> <span class="o">...</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="c1"># return_dict=True</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">],</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedResult</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span> <span class="o">...</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">],</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedResult</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]:</span> <span class="o">...</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">return_dict</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">],</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedResult</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">]]:</span> <span class="o">...</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="c1"># return type unknown</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="nd">@overload</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span> <span class="o">...</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"mean"</span><span class="p">,</span> <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>        <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        Generate one or more embeddings.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">            text: A text or list of texts to generate embeddings for.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">            prefix: The model-specific prefix representing the embedding task, without the trailing colon. For Nomic</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">                Embed, this can be `search_query`, `search_document`, `classification`, or `clustering`. Defaults to</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">                `search_document` or equivalent if known; otherwise, you must explicitly pass a prefix or an empty</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">                string if none applies.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">            dimensionality: The embedding dimension, for use with Matryoshka-capable models. Defaults to full-size.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">            long_text_mode: How to handle texts longer than the model can accept. One of `mean` or `truncate`.</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">            return_dict: Return the result as a dict that includes the number of prompt tokens processed.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">            atlas: Try to be fully compatible with the Atlas API. Currently, this means texts longer than 8192 tokens</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">                with long_text_mode="mean" will raise an error. Disabled by default.</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">            cancel_cb: Called with arguments (batch_sizes, backend_name). Return true to cancel embedding.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">            With return_dict=False, an embedding or list of embeddings of your text(s).</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">            With return_dict=True, a dict with keys 'embeddings' and 'n_prompt_tokens'.</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">            CancellationError: If cancel_cb returned True and embedding was canceled.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        """</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="k">if</span> <span class="n">dimensionality</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="n">dimensionality</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>            <span class="k">if</span> <span class="n">dimensionality</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Dimensionality must be None or a positive integer, got </span><span class="si">{</span><span class="n">dimensionality</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>            <span class="k">if</span> <span class="n">dimensionality</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">MIN_DIMENSIONALITY</span><span class="p">:</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>                    <span class="sa">f</span><span class="s1">'Dimensionality </span><span class="si">{</span><span class="n">dimensionality</span><span class="si">}</span><span class="s1"> is less than the suggested minimum of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">MIN_DIMENSIONALITY</span><span class="si">}</span><span class="s1">.'</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>                    <span class="s1">' Performance may be degraded.'</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>                <span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>            <span class="n">do_mean</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"mean"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">"truncate"</span><span class="p">:</span> <span class="kc">False</span><span class="p">}[</span><span class="n">long_text_mode</span><span class="p">]</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Long text mode must be one of 'mean' or 'truncate', got </span><span class="si">{</span><span class="n">long_text_mode</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpt4all</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">,</span> <span class="n">do_mean</span><span class="p">,</span> <span class="n">atlas</span><span class="p">,</span> <span class="n">cancel_cb</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="k">return</span> <span class="n">result</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="k">else</span> <span class="n">result</span><span class="p">[</span><span class="s1">'embeddings'</span><span class="p">]</span>
</code></pre></div></td></tr></tbody></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.Embed4All.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Constructor</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code>n_threads</code></b>
              (<code>int | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>number of CPU threads used by GPT4All. Default is None, then the number of threads are determined automatically.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>device</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>The processing unit on which the embedding model will run. See the <code>GPT4All</code> constructor for more info.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>kwargs</code></b>
              (<code><span title="typing.Any">Any</span></code>, default:
                  <code>{}</code>
)
          
          <div class="doc-md-description">
            <p>Remaining keyword arguments are passed to the <code>GPT4All</code> constructor.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-48">48</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-49">49</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-50">50</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-51">51</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-52">52</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-53">53</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-54">54</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-55">55</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-56">56</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-57">57</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-58">58</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-59">59</a></span></pre></div></td><td class="code"><div><pre id="__code_30"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_30 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    Constructor</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        n_threads: number of CPU threads used by GPT4All. Default is None, then the number of threads are determined automatically.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        device: The processing unit on which the embedding model will run. See the `GPT4All` constructor for more info.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        kwargs: Remaining keyword arguments are passed to the `GPT4All` constructor.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    """</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>    <span class="k">if</span> <span class="n">model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="n">model_name</span> <span class="o">=</span> <span class="s1">'all-MiniLM-L6-v2.gguf2.f16.gguf'</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">gpt4all</span> <span class="o">=</span> <span class="n">GPT4All</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.Embed4All.close" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">close</span><span class="p">()</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Delete the model instance and free associated system resources.</p>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-69">69</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-70">70</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-71">71</a></span></pre></div></td><td class="code"><div><pre id="__code_31"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_31 &gt; code"></button><code><a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="w">    </span><span class="sd">"""Delete the model instance and free associated system resources."""</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">gpt4all</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h5 id="gpt4all.gpt4all.Embed4All.embed" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">embed</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dimensionality</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">long_text_mode</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">atlas</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cancel_cb</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Generate one or more embeddings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code>text</code></b>
              (<code>str | list[str]</code>)
          
          <div class="doc-md-description">
            <p>A text or list of texts to generate embeddings for.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>prefix</code></b>
              (<code>str | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>The model-specific prefix representing the embedding task, without the trailing colon. For Nomic
Embed, this can be <code>search_query</code>, <code>search_document</code>, <code>classification</code>, or <code>clustering</code>. Defaults to
<code>search_document</code> or equivalent if known; otherwise, you must explicitly pass a prefix or an empty
string if none applies.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>dimensionality</code></b>
              (<code>int | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>The embedding dimension, for use with Matryoshka-capable models. Defaults to full-size.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>long_text_mode</code></b>
              (<code>str</code>, default:
                  <code>'mean'</code>
)
          
          <div class="doc-md-description">
            <p>How to handle texts longer than the model can accept. One of <code>mean</code> or <code>truncate</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>return_dict</code></b>
              (<code>bool</code>, default:
                  <code>False</code>
)
          
          <div class="doc-md-description">
            <p>Return the result as a dict that includes the number of prompt tokens processed.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>atlas</code></b>
              (<code>bool</code>, default:
                  <code>False</code>
)
          
          <div class="doc-md-description">
            <p>Try to be fully compatible with the Atlas API. Currently, this means texts longer than 8192 tokens
with long_text_mode="mean" will raise an error. Disabled by default.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code>cancel_cb</code></b>
              (<code><span title="gpt4all._pyllmodel.EmbCancelCallbackType">EmbCancelCallbackType</span> | None</code>, default:
                  <code>None</code>
)
          
          <div class="doc-md-description">
            <p>Called with arguments (batch_sizes, backend_name). Return true to cancel embedding.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><span title="typing.Any">Any</span></code>
          
          <div class="doc-md-description">
            <p>With return_dict=False, an embedding or list of embeddings of your text(s).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
              <code><span title="typing.Any">Any</span></code>
          
          <div class="doc-md-description">
            <p>With return_dict=True, a dict with keys 'embeddings' and 'n_prompt_tokens'.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Raises:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code><span title="gpt4all._pyllmodel.CancellationError">CancellationError</span></code>
            
          <div class="doc-md-description">
            <p>If cancel_cb returned True and embedding was canceled.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>gpt4all/gpt4all.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tbody><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-117">117</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-118">118</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-119">119</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-120">120</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-121">121</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-122">122</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-123">123</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-124">124</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-125">125</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-126">126</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-127">127</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-128">128</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-129">129</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-130">130</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-131">131</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-132">132</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-133">133</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-134">134</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-135">135</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-136">136</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-137">137</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-138">138</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-139">139</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-140">140</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-141">141</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-142">142</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-143">143</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-144">144</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-145">145</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-146">146</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-147">147</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-148">148</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-149">149</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-150">150</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-151">151</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-152">152</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-153">153</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-154">154</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-155">155</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-156">156</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-157">157</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-158">158</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-159">159</a></span>
<span class="normal"><a href="https://docs.gpt4all.io/gpt4all_python/ref.html#__codelineno-0-160">160</a></span></pre></div></td><td class="code"><div><pre id="__code_32"><span></span><button class="md-clipboard md-icon" title="Copy to clipboard" data-clipboard-target="#__code_32 &gt; code"></button><code tabindex="0"><a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="k">def</span> <span class="nf">embed</span><span class="p">(</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="n">long_text_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"mean"</span><span class="p">,</span> <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">atlas</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="n">cancel_cb</span><span class="p">:</span> <span class="n">EmbCancelCallbackType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    Generate one or more embeddings.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        text: A text or list of texts to generate embeddings for.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        prefix: The model-specific prefix representing the embedding task, without the trailing colon. For Nomic</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">            Embed, this can be `search_query`, `search_document`, `classification`, or `clustering`. Defaults to</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">            `search_document` or equivalent if known; otherwise, you must explicitly pass a prefix or an empty</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">            string if none applies.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        dimensionality: The embedding dimension, for use with Matryoshka-capable models. Defaults to full-size.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">        long_text_mode: How to handle texts longer than the model can accept. One of `mean` or `truncate`.</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">        return_dict: Return the result as a dict that includes the number of prompt tokens processed.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">        atlas: Try to be fully compatible with the Atlas API. Currently, this means texts longer than 8192 tokens</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">            with long_text_mode="mean" will raise an error. Disabled by default.</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">        cancel_cb: Called with arguments (batch_sizes, backend_name). Return true to cancel embedding.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">        With return_dict=False, an embedding or list of embeddings of your text(s).</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">        With return_dict=True, a dict with keys 'embeddings' and 'n_prompt_tokens'.</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">        CancellationError: If cancel_cb returned True and embedding was canceled.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">    """</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="k">if</span> <span class="n">dimensionality</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="n">dimensionality</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="k">if</span> <span class="n">dimensionality</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Dimensionality must be None or a positive integer, got </span><span class="si">{</span><span class="n">dimensionality</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="k">if</span> <span class="n">dimensionality</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">MIN_DIMENSIONALITY</span><span class="p">:</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>                <span class="sa">f</span><span class="s1">'Dimensionality </span><span class="si">{</span><span class="n">dimensionality</span><span class="si">}</span><span class="s1"> is less than the suggested minimum of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">MIN_DIMENSIONALITY</span><span class="si">}</span><span class="s1">.'</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>                <span class="s1">' Performance may be degraded.'</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>            <span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="n">do_mean</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"mean"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">"truncate"</span><span class="p">:</span> <span class="kc">False</span><span class="p">}[</span><span class="n">long_text_mode</span><span class="p">]</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Long text mode must be one of 'mean' or 'truncate', got </span><span class="si">{</span><span class="n">long_text_mode</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpt4all</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">dimensionality</span><span class="p">,</span> <span class="n">do_mean</span><span class="p">,</span> <span class="n">atlas</span><span class="p">,</span> <span class="n">cancel_cb</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="k">return</span> <span class="n">result</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="k">else</span> <span class="n">result</span><span class="p">[</span><span class="s1">'embeddings'</span><span class="p">]</span>
</code></pre></div></td></tr></tbody></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright  2024 Nomic, Inc
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy", "navigation.instant", "navigation.tracking", "navigation.sections"], "search": "../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="./SDK Reference - GPT4All_files/bundle.56dfad97.min.js.download"></script>
      
    
  <script defer="" src="./SDK Reference - GPT4All_files/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon="{&quot;rayId&quot;:&quot;8c11f0c8484a8dcf&quot;,&quot;version&quot;:&quot;2024.8.0&quot;,&quot;serverTiming&quot;:{&quot;name&quot;:{&quot;cfExtPri&quot;:true,&quot;cfL4&quot;:true}},&quot;token&quot;:&quot;9d54bc6d581142b6aceaafc639be4f15&quot;,&quot;b&quot;:1}" crossorigin="anonymous"></script>

</body></html>